{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A/B Testing Masterclass: The Complete Experimentation Lifecycle\n",
    "## Cookie Cats Mobile Game Analysis\n",
    "\n",
    "---\n",
    "\n",
    "## üéØ What This Notebook Is Really About\n",
    "\n",
    "**In data science interviews, A/B testing is rarely just about p-values and confidence intervals.**\n",
    "\n",
    "It's a proxy for something much bigger. Interviewers use A/B testing questions to understand:\n",
    "- **How you think** through problems from start to finish\n",
    "- **How you deal with ambiguity** when there's no single correct answer\n",
    "- **How you turn messy data into decisions** that actually matter to the business\n",
    "\n",
    "This is where many strong candidates struggle‚Äînot because they don't know the math (most do), but because they lack a **clear mental model for the full A/B testing lifecycle**. They jump straight to analysis when they should be asking: *What hypothesis are we testing? Why these metrics? What trade-offs are we accepting?*\n",
    "\n",
    "### The A/B Testing Lifecycle\n",
    "\n",
    "This notebook follows the complete experimentation lifecycle:\n",
    "\n",
    "```\n",
    "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "‚îÇ  1. FRAME THE QUESTION                                              ‚îÇ\n",
    "‚îÇ     ‚îî‚îÄ‚îÄ What business problem are we solving?                       ‚îÇ\n",
    "‚îÇ     ‚îî‚îÄ‚îÄ What's our hypothesis and why?                              ‚îÇ\n",
    "‚îÇ                                                                     ‚îÇ\n",
    "‚îÇ  2. CHOOSE METRICS                                                  ‚îÇ\n",
    "‚îÇ     ‚îî‚îÄ‚îÄ Primary (what we're optimizing)                             ‚îÇ\n",
    "‚îÇ     ‚îî‚îÄ‚îÄ Guardrails (what we can't harm)                             ‚îÇ\n",
    "‚îÇ     ‚îî‚îÄ‚îÄ Trade-offs between them                                     ‚îÇ\n",
    "‚îÇ                                                                     ‚îÇ\n",
    "‚îÇ  3. VALIDATE THE EXPERIMENT                                         ‚îÇ\n",
    "‚îÇ     ‚îî‚îÄ‚îÄ SRM check (did randomization work?)                         ‚îÇ\n",
    "‚îÇ     ‚îî‚îÄ‚îÄ Data quality validation                                     ‚îÇ\n",
    "‚îÇ                                                                     ‚îÇ\n",
    "‚îÇ  4. ANALYZE RESULTS                                                 ‚îÇ\n",
    "‚îÇ     ‚îî‚îÄ‚îÄ Statistical tests (the math part)                           ‚îÇ\n",
    "‚îÇ     ‚îî‚îÄ‚îÄ Practical significance (does it matter?)                    ‚îÇ\n",
    "‚îÇ                                                                     ‚îÇ\n",
    "‚îÇ  5. INTERPRET & DECIDE                                              ‚îÇ\n",
    "‚îÇ     ‚îî‚îÄ‚îÄ What does this mean for the business?                       ‚îÇ\n",
    "‚îÇ     ‚îî‚îÄ‚îÄ Ship / Hold / Abandon decision                              ‚îÇ\n",
    "‚îÇ     ‚îî‚îÄ‚îÄ What are we uncertain about?                                ‚îÇ\n",
    "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "```\n",
    "\n",
    "**Foundations first, sophistication later.** This notebook covers the fundamentals that every experimentation analysis should include. Later notebooks (Criteo, Marketing) build on this foundation with advanced techniques.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Objectives\n",
    "\n",
    "By the end of this notebook, you will be able to:\n",
    "\n",
    "1. **Frame a hypothesis** properly (not just state it)\n",
    "2. **Choose metrics** and articulate trade-offs between them\n",
    "3. **Validate randomization** using two-stage SRM gating\n",
    "4. **Interpret results** with multiple testing correction\n",
    "5. **Make decisions** using the Ship/Hold/Abandon framework\n",
    "6. **Communicate findings** in business terms, not just statistics\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase 1: Frame the Question\n",
    "\n",
    "### The Business Context\n",
    "\n",
    "**Cookie Cats** is a popular mobile puzzle game. Like many free-to-play games, it uses \"gates\"‚Äîpoints where players must wait or make an in-app purchase to continue.\n",
    "\n",
    "Gates serve two purposes:\n",
    "1. **Monetization**: Players can pay to skip the wait\n",
    "2. **Engagement**: Breaks prevent burnout and give players a reason to return\n",
    "\n",
    "### üí° Interview Insight: How to Frame a Hypothesis\n",
    "\n",
    "In interviews, many candidates state their hypothesis as a simple prediction:\n",
    "\n",
    "> *\"Moving the gate will increase retention.\"*\n",
    "\n",
    "Strong candidates frame it with **reasoning** and **risks**:\n",
    "\n",
    "> *\"Moving the gate from level 30 to level 40 might improve early retention because players get more uninterrupted gameplay before hitting the first paywall‚Äîreducing frustration during the critical onboarding period. However, there's a risk: players who reach level 40 before any gate may become so invested that the sudden stop feels more jarring, causing them to quit entirely rather than wait or pay.\"*\n",
    "\n",
    "The second framing shows you've thought about:\n",
    "- **The mechanism** (why you think it will work)\n",
    "- **The counterfactual** (what could go wrong)\n",
    "- **The trade-off** (early retention vs. long-term engagement)\n",
    "\n",
    "---\n",
    "\n",
    "### Our Experimental Design\n",
    "\n",
    "| Aspect | Control (gate_30) | Treatment (gate_40) |\n",
    "|--------|-------------------|---------------------|\n",
    "| Gate Position | Level 30 | Level 40 |\n",
    "| Allocation | 50% | 50% |\n",
    "| Sample Size | ~45,000 | ~45,000 |\n",
    "\n",
    "**Hypothesis**: Moving the gate later will improve 1-day retention by reducing early frustration.\n",
    "\n",
    "**Risk**: Players may quit at higher levels when they finally hit the gate.\n",
    "\n",
    "**Key Insight**: Notice we're running a **50/50 randomized controlled trial (RCT)**‚Äîthis is critical for SRM validation later.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase 2: Choose Metrics (and Understand Trade-offs)\n",
    "\n",
    "### üí° Interview Insight: Why Metric Selection Matters\n",
    "\n",
    "One of the most common interview questions is: *\"What metrics would you use?\"*\n",
    "\n",
    "Weak answers list metrics. Strong answers explain the **hierarchy** and **trade-offs**:\n",
    "\n",
    "#### Our Metric Framework\n",
    "\n",
    "| Type | Metric | Why This Metric | Trade-off |\n",
    "|------|--------|-----------------|------------|\n",
    "| **Primary** | 1-Day Retention | Most sensitive to onboarding changes; captures immediate impact | May miss long-term effects |\n",
    "| **Secondary** | 7-Day Retention | Captures whether players stick around | Slower to move; more variance |\n",
    "| **Guardrail** | Engagement (rounds/player) | Ensures we're not gaming retention at the cost of depth | Can increase even if quality decreases |\n",
    "\n",
    "### Why These Specific Metrics?\n",
    "\n",
    "**1-Day Retention as Primary:**\n",
    "- Moves faster than 7-day (shorter feedback loop)\n",
    "- Most sensitive to early game experience\n",
    "- Strong predictor of long-term value\n",
    "\n",
    "**7-Day Retention as Guardrail (not secondary):**\n",
    "- The gate change could improve day-1 but hurt week-1\n",
    "- We need to ensure we're not just delaying churn\n",
    "\n",
    "**Engagement as Guardrail:**\n",
    "- A player who returns but plays less is a warning sign\n",
    "- Prevents Goodhart's Law (optimizing the metric, not the goal)\n",
    "\n",
    "### üí° Trade-off Discussion\n",
    "\n",
    "**What we're optimizing**: Short-term retention (1-day)\n",
    "\n",
    "**What we're protecting**: Long-term retention (7-day) and engagement depth\n",
    "\n",
    "**The implicit bet**: We believe improving early retention will have positive downstream effects, but we're setting guardrails to detect if we're wrong.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Modules loaded successfully\n"
     ]
    }
   ],
   "source": [
    "# Core imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# A/B Testing modules\n",
    "from ab_testing.data import loaders\n",
    "from ab_testing.core import randomization, frequentist\n",
    "from ab_testing.advanced import multiple_testing, ratio_metrics\n",
    "from ab_testing.diagnostics import guardrails\n",
    "\n",
    "# Set up plotting\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "%matplotlib inline\n",
    "\n",
    "print(\"‚úì Modules loaded successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Cookie Cats dataset from data\\raw\\cookie_cats\\cookie_cats.csv...\n",
      "Loaded Cookie Cats dataset: 90,189 rows, 6 columns\n",
      "  7-day retention (gate_30): 19.02%\n",
      "  7-day retention (gate_40): 18.20%\n",
      "Dataset loaded: 90,189 players\n",
      "\n",
      "Columns: ['userid', 'version', 'sum_gamerounds', 'retention_1', 'retention_7', 'treatment']\n",
      "\n",
      "First few rows:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userid</th>\n",
       "      <th>version</th>\n",
       "      <th>sum_gamerounds</th>\n",
       "      <th>retention_1</th>\n",
       "      <th>retention_7</th>\n",
       "      <th>treatment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>116</td>\n",
       "      <td>gate_30</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>337</td>\n",
       "      <td>gate_30</td>\n",
       "      <td>38</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>377</td>\n",
       "      <td>gate_40</td>\n",
       "      <td>165</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>483</td>\n",
       "      <td>gate_40</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>488</td>\n",
       "      <td>gate_40</td>\n",
       "      <td>179</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userid  version  sum_gamerounds  retention_1  retention_7  treatment\n",
       "0     116  gate_30               3        False        False          0\n",
       "1     337  gate_30              38         True        False          0\n",
       "2     377  gate_40             165         True        False          1\n",
       "3     483  gate_40               1        False        False          1\n",
       "4     488  gate_40             179         True         True          1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the Cookie Cats dataset\n",
    "df = loaders.load_cookie_cats(sample_frac=1.0)\n",
    "\n",
    "print(f\"Dataset loaded: {len(df):,} players\")\n",
    "print(f\"\\nColumns: {list(df.columns)}\")\n",
    "print(f\"\\nFirst few rows:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Summary\n",
      "==================================================\n",
      "\n",
      "Group distribution:\n",
      "version\n",
      "gate_40    45489\n",
      "gate_30    44700\n",
      "Name: count, dtype: int64\n",
      "\n",
      "1-Day Retention by group:\n",
      "version\n",
      "gate_30    0.448188\n",
      "gate_40    0.442283\n",
      "Name: retention_1, dtype: float64\n",
      "\n",
      "7-Day Retention by group:\n",
      "version\n",
      "gate_30    0.190201\n",
      "gate_40    0.182000\n",
      "Name: retention_7, dtype: float64\n",
      "\n",
      "Game rounds statistics:\n",
      "           count       mean         std  min  25%   50%   75%      max\n",
      "version                                                               \n",
      "gate_30  44700.0  52.456264  256.716423  0.0  5.0  17.0  50.0  49854.0\n",
      "gate_40  45489.0  51.298776  103.294416  0.0  5.0  16.0  52.0   2640.0\n"
     ]
    }
   ],
   "source": [
    "# Understand the data\n",
    "print(\"Dataset Summary\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"\\nGroup distribution:\")\n",
    "print(df['version'].value_counts())\n",
    "print(f\"\\n1-Day Retention by group:\")\n",
    "print(df.groupby('version')['retention_1'].mean())\n",
    "print(f\"\\n7-Day Retention by group:\")\n",
    "print(df.groupby('version')['retention_7'].mean())\n",
    "print(f\"\\nGame rounds statistics:\")\n",
    "print(df.groupby('version')['sum_gamerounds'].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Phase 3: Validate the Experiment\n",
    "\n",
    "### Step 1: Sample Ratio Mismatch (SRM) Check\n",
    "\n",
    "### üí° Interview Insight: Why Validation Comes Before Analysis\n",
    "\n",
    "Many candidates jump straight to analyzing results. Experienced practitioners **always validate first**.\n",
    "\n",
    "> *\"Before we look at any treatment effects, we need to verify the experiment ran correctly. If randomization failed, all downstream analysis is meaningless.\"*\n",
    "\n",
    "This is a lifecycle principle: **garbage in, garbage out**.\n",
    "\n",
    "### What is SRM?\n",
    "\n",
    "Sample Ratio Mismatch occurs when actual group sizes don't match expected allocation. For a 50/50 split, we expect roughly equal groups (allowing for random variation).\n",
    "\n",
    "**Why SRM is Critical:**\n",
    "\n",
    "If groups are imbalanced beyond what random chance would produce, it indicates:\n",
    "- Bug in randomization code\n",
    "- Tracking/logging issues (events lost for one group)\n",
    "- Group-specific crashes (treatment causes technical problems)\n",
    "- Bot traffic concentrated in one group\n",
    "\n",
    "**Industry Practice:**\n",
    "- Microsoft: Blocks all analysis if SRM detected\n",
    "- Netflix: Triggers immediate engineering alerts\n",
    "- Booking.com: Uses stricter alpha (0.001)\n",
    "\n",
    "### Two-Stage SRM Gating\n",
    "\n",
    "With large samples (90K+ users), even tiny deviations become statistically significant. We use a two-stage approach:\n",
    "\n",
    "1. **Statistical Significance**: p-value < 0.01 (chi-square test)\n",
    "2. **Practical Significance**: Deviation > 1 percentage point from expected\n",
    "\n",
    "**Only if BOTH conditions are met do we halt the analysis.**\n",
    "\n",
    "This prevents false alarms from large-sample statistical sensitivity.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group Distribution Analysis\n",
      "==================================================\n",
      "Total users: 90,189\n",
      "\n",
      "Control (gate_30): 44,700 (49.56%)\n",
      "Treatment (gate_40): 45,489 (50.44%)\n",
      "\n",
      "Expected: 50% / 50%\n",
      "Deviation from expected: 0.4374%\n"
     ]
    }
   ],
   "source": [
    "# Calculate actual group proportions\n",
    "group_counts = df['version'].value_counts()\n",
    "total = len(df)\n",
    "\n",
    "control_count = group_counts.get('gate_30', 0)\n",
    "treatment_count = group_counts.get('gate_40', 0)\n",
    "\n",
    "actual_control_ratio = control_count / total\n",
    "actual_treatment_ratio = treatment_count / total\n",
    "\n",
    "print(\"Group Distribution Analysis\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Total users: {total:,}\")\n",
    "print(f\"\\nControl (gate_30): {control_count:,} ({actual_control_ratio:.2%})\")\n",
    "print(f\"Treatment (gate_40): {treatment_count:,} ({actual_treatment_ratio:.2%})\")\n",
    "print(f\"\\nExpected: 50% / 50%\")\n",
    "print(f\"Deviation from expected: {abs(actual_control_ratio - 0.5):.4%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SRM Check Results\n",
      "==================================================\n",
      "\n",
      "Statistical test:\n",
      "  Chi-square statistic: 6.9024\n",
      "  P-value: 0.008608\n",
      "  Statistically significant: True\n",
      "\n",
      "Practical significance:\n",
      "  Actual ratio (control): 0.4956\n",
      "  Expected ratio (control): 0.5\n",
      "  Deviation: 0.0044\n",
      "  Severe (>1%): False\n"
     ]
    }
   ],
   "source": [
    "# Run formal SRM check using two-stage gating\n",
    "srm_result = randomization.srm_check(\n",
    "    n_control=control_count,\n",
    "    n_treatment=treatment_count,\n",
    "    expected_ratio=[0.5, 0.5],  # Expected 50/50 split as list\n",
    "    alpha=0.01\n",
    ")\n",
    "\n",
    "print(\"SRM Check Results\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"\\nStatistical test:\")\n",
    "print(f\"  Chi-square statistic: {srm_result['chi2_statistic']:.4f}\")\n",
    "print(f\"  P-value: {srm_result['p_value']:.6f}\")\n",
    "print(f\"  Statistically significant: {srm_result['srm_detected']}\")\n",
    "\n",
    "print(f\"\\nPractical significance:\")\n",
    "print(f\"  Actual ratio (control): {srm_result['ratio_control']:.4f}\")\n",
    "print(f\"  Expected ratio (control): 0.5\")\n",
    "print(f\"  Deviation: {srm_result['max_pp_deviation']:.4f}\")\n",
    "print(f\"  Severe (>1%): {srm_result['srm_severe']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Two-Stage SRM Gating\n",
      "==================================================\n",
      "\n",
      "[1] Statistical Significance: ‚ö†Ô∏è YES\n",
      "    (p-value = 0.008608, threshold = 0.01)\n",
      "\n",
      "[2] Practical Significance: ‚úì NO\n",
      "    (deviation = 0.0044, threshold = 0.01)\n",
      "\n",
      "==================================================\n",
      "‚ö†Ô∏è  WARNING: Statistical but not practical significance.\n",
      "   This is common with large samples (90K+).\n",
      "   Proceeding with caution.\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# Apply two-stage gating logic\n",
    "IS_RCT = True  # This is a designed 50/50 experiment\n",
    "PRACTICAL_THRESHOLD = 0.01  # 1 percentage point\n",
    "\n",
    "# Use the correct keys from srm_result\n",
    "# max_pp_deviation is the calculated deviation from expected ratio\n",
    "deviation = srm_result['max_pp_deviation']\n",
    "statistically_significant = srm_result['srm_detected']\n",
    "practically_significant = srm_result['practical_significant']\n",
    "\n",
    "print(\"\\nTwo-Stage SRM Gating\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"\\n[1] Statistical Significance: {'‚ö†Ô∏è YES' if statistically_significant else '‚úì NO'}\")\n",
    "print(f\"    (p-value = {srm_result['p_value']:.6f}, threshold = 0.01)\")\n",
    "print(f\"\\n[2] Practical Significance: {'‚ö†Ô∏è YES' if practically_significant else '‚úì NO'}\")\n",
    "print(f\"    (deviation = {deviation:.4f}, threshold = {PRACTICAL_THRESHOLD})\")\n",
    "\n",
    "if IS_RCT and srm_result['srm_severe']:\n",
    "    print(\"\\n\" + \"=\" * 50)\n",
    "    print(\"üö´ HARD GATE: Analysis should STOP here.\")\n",
    "    print(\"   Investigate randomization before proceeding.\")\n",
    "    print(\"=\" * 50)\n",
    "elif srm_result['srm_warning']:\n",
    "    print(\"\\n\" + \"=\" * 50)\n",
    "    print(\"‚ö†Ô∏è  WARNING: Statistical but not practical significance.\")\n",
    "    print(\"   This is common with large samples (90K+).\")\n",
    "    print(\"   Proceeding with caution.\")\n",
    "    print(\"=\" * 50)\n",
    "else:\n",
    "    print(\"\\n\" + \"=\" * 50)\n",
    "    print(\"‚úì SRM CHECK PASSED\")\n",
    "    print(\"  Randomization appears to have worked correctly.\")\n",
    "    print(\"  Proceeding to treatment effect analysis.\")\n",
    "    print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üí° Interview Insight: Explaining SRM Decisions\n",
    "\n",
    "In an interview, you might be asked: *\"The SRM check is statistically significant. Should we stop?\"*\n",
    "\n",
    "**Weak answer**: *\"Yes, the p-value is below 0.01.\"*\n",
    "\n",
    "**Strong answer**: *\"It depends. With 90K users, even a 0.3% deviation becomes statistically significant. The key question is whether the deviation is large enough to bias our results. A 49.7% vs 50.3% split won't meaningfully affect treatment effect estimates. However, a 45% vs 55% split would be concerning. I'd look at the practical significance‚Äîis the deviation large enough to matter?\"*\n",
    "\n",
    "This shows you understand the difference between **statistical** and **practical** significance.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase 4: Analyze Results\n",
    "\n",
    "### Step 2: Primary Metric Analysis (1-Day Retention)\n",
    "\n",
    "Now that we've validated the experiment, we can analyze treatment effects.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Sizes\n",
      "========================================\n",
      "Control: 44,700\n",
      "Treatment: 45,489\n"
     ]
    }
   ],
   "source": [
    "# Prepare data for analysis\n",
    "control_df = df[df['version'] == 'gate_30']\n",
    "treatment_df = df[df['version'] == 'gate_40']\n",
    "\n",
    "# Extract arrays for testing\n",
    "control_retention_1d = control_df['retention_1'].values\n",
    "treatment_retention_1d = treatment_df['retention_1'].values\n",
    "\n",
    "print(\"Sample Sizes\")\n",
    "print(\"=\" * 40)\n",
    "print(f\"Control: {len(control_retention_1d):,}\")\n",
    "print(f\"Treatment: {len(treatment_retention_1d):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1-Day Retention Analysis\n",
      "==================================================\n",
      "\n",
      "Control:   0.4482 (44.82%)\n",
      "Treatment: 0.4423 (44.23%)\n",
      "\n",
      "Absolute difference: -0.0059\n",
      "Relative lift: -1.32%\n",
      "\n",
      "95% CI: [-0.0124, 0.0006]\n",
      "P-value: 0.074410\n",
      "\n",
      "Statistically significant: False\n"
     ]
    }
   ],
   "source": [
    "# Run z-test for 1-day retention\n",
    "# z_test_proportions expects: x_control (successes), n_control (total), x_treatment, n_treatment\n",
    "x_control_1d = control_retention_1d.sum()  # Number of retained players\n",
    "n_control_1d = len(control_retention_1d)   # Total control players\n",
    "x_treatment_1d = treatment_retention_1d.sum()\n",
    "n_treatment_1d = len(treatment_retention_1d)\n",
    "\n",
    "retention_1d_result = frequentist.z_test_proportions(\n",
    "    x_control=x_control_1d,\n",
    "    n_control=n_control_1d,\n",
    "    x_treatment=x_treatment_1d,\n",
    "    n_treatment=n_treatment_1d,\n",
    "    alpha=0.05\n",
    ")\n",
    "\n",
    "print(\"1-Day Retention Analysis\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"\\nControl:   {retention_1d_result['p_control']:.4f} ({retention_1d_result['p_control']:.2%})\")\n",
    "print(f\"Treatment: {retention_1d_result['p_treatment']:.4f} ({retention_1d_result['p_treatment']:.2%})\")\n",
    "print(f\"\\nAbsolute difference: {retention_1d_result['absolute_lift']:.4f}\")\n",
    "print(f\"Relative lift: {retention_1d_result['relative_lift']:.2%}\")\n",
    "print(f\"\\n95% CI: [{retention_1d_result['ci_lower']:.4f}, {retention_1d_result['ci_upper']:.4f}]\")\n",
    "print(f\"P-value: {retention_1d_result['p_value']:.6f}\")\n",
    "print(f\"\\nStatistically significant: {retention_1d_result['significant']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üí° Interview Insight: Interpreting Results\n",
    "\n",
    "Notice that the result might show a **negative** treatment effect (retention decreased when we moved the gate later). \n",
    "\n",
    "In an interview, you might be asked: *\"The results contradict your hypothesis. What do you conclude?\"*\n",
    "\n",
    "**Weak answer**: *\"The experiment failed.\"*\n",
    "\n",
    "**Strong answer**: *\"This is actually valuable information. It suggests our mental model was wrong‚Äîdelaying the gate doesn't reduce frustration, it may actually increase it. The sunk-cost hypothesis might be at play: players who've invested 40 levels feel more entitled to continue and react worse to being stopped. This gives us insight for future experiments‚Äîmaybe the gate timing matters less than how it's presented.\"*\n",
    "\n",
    "Experiments that disprove hypotheses are still successful experiments.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Multiple Testing Correction\n",
    "\n",
    "We're testing multiple metrics (1-day retention, 7-day retention). This inflates our false positive rate.\n",
    "\n",
    "**The Problem:**\n",
    "- Testing 1 metric at Œ±=0.05: 5% false positive rate\n",
    "- Testing 2 metrics at Œ±=0.05: 1 - (0.95)¬≤ = 9.75% false positive rate\n",
    "- Testing 5 metrics at Œ±=0.05: 1 - (0.95)‚Åµ = 22.6% false positive rate\n",
    "\n",
    "**The Solution: Benjamini-Hochberg FDR Control**\n",
    "\n",
    "Instead of controlling the probability of ANY false positive (FWER), we control the expected proportion of false positives among rejected hypotheses (FDR).\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7-Day Retention Analysis\n",
      "==================================================\n",
      "\n",
      "Control:   0.1902 (19.02%)\n",
      "Treatment: 0.1820 (18.20%)\n",
      "\n",
      "Relative lift: -4.31%\n",
      "P-value: 0.001554\n",
      "\n",
      "Statistically significant: True\n"
     ]
    }
   ],
   "source": [
    "# Test 7-day retention\n",
    "control_retention_7d = control_df['retention_7'].values\n",
    "treatment_retention_7d = treatment_df['retention_7'].values\n",
    "\n",
    "# Convert to counts for z_test_proportions\n",
    "x_control_7d = control_retention_7d.sum()\n",
    "n_control_7d = len(control_retention_7d)\n",
    "x_treatment_7d = treatment_retention_7d.sum()\n",
    "n_treatment_7d = len(treatment_retention_7d)\n",
    "\n",
    "retention_7d_result = frequentist.z_test_proportions(\n",
    "    x_control=x_control_7d,\n",
    "    n_control=n_control_7d,\n",
    "    x_treatment=x_treatment_7d,\n",
    "    n_treatment=n_treatment_7d,\n",
    "    alpha=0.05\n",
    ")\n",
    "\n",
    "print(\"7-Day Retention Analysis\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"\\nControl:   {retention_7d_result['p_control']:.4f} ({retention_7d_result['p_control']:.2%})\")\n",
    "print(f\"Treatment: {retention_7d_result['p_treatment']:.4f} ({retention_7d_result['p_treatment']:.2%})\")\n",
    "print(f\"\\nRelative lift: {retention_7d_result['relative_lift']:.2%}\")\n",
    "print(f\"P-value: {retention_7d_result['p_value']:.6f}\")\n",
    "print(f\"\\nStatistically significant: {retention_7d_result['significant']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiple Testing Correction (Benjamini-Hochberg)\n",
      "============================================================\n",
      "\n",
      "FDR level: 5.00%\n",
      "\n",
      "Metric                    P-value   Adjusted P  Significant\n",
      "------------------------------------------------------------\n",
      "1-Day Retention          0.074410     0.074410        False\n",
      "7-Day Retention          0.001554     0.003108         True\n",
      "\n",
      "Number of discoveries: 1\n"
     ]
    }
   ],
   "source": [
    "# Apply Benjamini-Hochberg correction\n",
    "p_values = [\n",
    "    retention_1d_result['p_value'],\n",
    "    retention_7d_result['p_value']\n",
    "]\n",
    "metric_names = ['1-Day Retention', '7-Day Retention']\n",
    "\n",
    "bh_result = multiple_testing.benjamini_hochberg(\n",
    "    p_values=p_values,\n",
    "    alpha=0.05\n",
    ")\n",
    "\n",
    "print(\"Multiple Testing Correction (Benjamini-Hochberg)\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nFDR level: {bh_result['alpha']:.2%}\")\n",
    "print(f\"\\n{'Metric':<20} {'P-value':>12} {'Adjusted P':>12} {'Significant':>12}\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "# Use correct keys: 'significant' (not 'reject_null'), 'n_significant' (not 'n_discoveries')\n",
    "for i, metric in enumerate(metric_names):\n",
    "    print(f\"{metric:<20} {p_values[i]:>12.6f} {bh_result['adjusted_p_values'][i]:>12.6f} {str(bh_result['significant'][i]):>12}\")\n",
    "\n",
    "print(f\"\\nNumber of discoveries: {bh_result['n_significant']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üí° Interview Insight: When to Correct for Multiple Testing\n",
    "\n",
    "*\"When should you use Bonferroni vs. Benjamini-Hochberg?\"*\n",
    "\n",
    "**Strong answer**: *\"It depends on the cost of false positives vs. false negatives. Bonferroni is more conservative‚Äîit controls the probability of any false positive, which is appropriate when false positives are very costly (like medical trials). Benjamini-Hochberg is less conservative‚Äîit controls the expected proportion of false positives among discoveries, which is appropriate when you're doing exploratory analysis and can tolerate some false positives in exchange for not missing true effects. For A/B tests with 2-5 metrics, BH is usually the right choice because we don't want to be so conservative that we miss real improvements.\"*\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Ratio Metrics (Delta Method)\n",
    "\n",
    "Engagement (game rounds per player) is a **ratio metric**. We can't simply compare means because the variance calculation is different.\n",
    "\n",
    "The **Delta Method** provides the correct standard error for ratios.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Engagement Analysis (Game Rounds per Player)\n",
      "==================================================\n",
      "\n",
      "Control mean:   52.46 rounds\n",
      "Treatment mean: 51.30 rounds\n",
      "\n",
      "Difference: -1.16 rounds\n",
      "Relative change: -2.21%\n",
      "\n",
      "95% CI: [-3.72, 1.40]\n",
      "P-value: 0.375921\n",
      "\n",
      "Statistically significant: False\n"
     ]
    }
   ],
   "source": [
    "# Extract engagement data\n",
    "control_rounds = control_df['sum_gamerounds'].values\n",
    "treatment_rounds = treatment_df['sum_gamerounds'].values\n",
    "\n",
    "# For ratio metric, we need numerator (total rounds) and denominator (player count)\n",
    "# In this case, we're computing rounds per player = mean rounds\n",
    "# Correct params: numerator_control, denominator_control, numerator_treatment, denominator_treatment\n",
    "ratio_result = ratio_metrics.ratio_metric_test(\n",
    "    numerator_control=control_rounds,\n",
    "    denominator_control=np.ones(len(control_rounds)),  # 1 player each\n",
    "    numerator_treatment=treatment_rounds,\n",
    "    denominator_treatment=np.ones(len(treatment_rounds)),\n",
    "    alpha=0.05\n",
    ")\n",
    "\n",
    "print(\"Engagement Analysis (Game Rounds per Player)\")\n",
    "print(\"=\" * 50)\n",
    "# Correct return keys: ratio_control, ratio_treatment, ratio_diff, relative_lift\n",
    "print(f\"\\nControl mean:   {ratio_result['ratio_control']:.2f} rounds\")\n",
    "print(f\"Treatment mean: {ratio_result['ratio_treatment']:.2f} rounds\")\n",
    "print(f\"\\nDifference: {ratio_result['ratio_diff']:.2f} rounds\")\n",
    "print(f\"Relative change: {ratio_result['relative_lift']:.2%}\")\n",
    "print(f\"\\n95% CI: [{ratio_result['ci_lower']:.2f}, {ratio_result['ci_upper']:.2f}]\")\n",
    "print(f\"P-value: {ratio_result['p_value']:.6f}\")\n",
    "print(f\"\\nStatistically significant: {ratio_result['significant']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Phase 5: Interpret and Decide\n",
    "\n",
    "### Step 5: Guardrail Evaluation\n",
    "\n",
    "Guardrails use **non-inferiority tests**: we're not trying to prove improvement, just that we haven't caused unacceptable harm.\n",
    "\n",
    "| Metric | Tolerance | Meaning |\n",
    "|--------|-----------|----------|\n",
    "| 7-Day Retention | -1% | We accept up to 1% relative decrease |\n",
    "| Engagement | -5% | We accept up to 5% relative decrease |\n",
    "\n",
    "These thresholds reflect **business judgment** about acceptable trade-offs.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guardrail 1: 7-Day Retention\n",
      "==================================================\n",
      "Tolerance: -1.0% (max allowed degradation)\n",
      "\n",
      "Control mean:   0.1902\n",
      "Treatment mean: 0.1820\n",
      "\n",
      "Relative change:    -4.31%\n",
      "95% CI lower bound: -6.55%\n",
      "\n",
      "Result: ‚úó FAILED\n"
     ]
    }
   ],
   "source": [
    "# Guardrail 1: 7-Day Retention (must not degrade more than 1%)\n",
    "guardrail_retention_7d = guardrails.non_inferiority_test(\n",
    "    control=control_retention_7d,\n",
    "    treatment=treatment_retention_7d,\n",
    "    delta=-0.01,  # Allow max 1% relative degradation\n",
    "    metric_type='relative',\n",
    "    alpha=0.05\n",
    ")\n",
    "guardrail_retention_7d['metric_name'] = '7-Day Retention'\n",
    "\n",
    "print(\"Guardrail 1: 7-Day Retention\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Tolerance: -1.0% (max allowed degradation)\")\n",
    "print(f\"\\nControl mean:   {guardrail_retention_7d['mean_control']:.4f}\")\n",
    "print(f\"Treatment mean: {guardrail_retention_7d['mean_treatment']:.4f}\")\n",
    "\n",
    "rel_change_7d = guardrail_retention_7d['difference'] / guardrail_retention_7d['mean_control']\n",
    "rel_ci_lower_7d = guardrail_retention_7d['ci_lower'] / guardrail_retention_7d['mean_control']\n",
    "\n",
    "print(f\"\\nRelative change:    {rel_change_7d:.2%}\")\n",
    "print(f\"95% CI lower bound: {rel_ci_lower_7d:.2%}\")\n",
    "print(f\"\\nResult: {'‚úì PASSED' if guardrail_retention_7d['passed'] else '‚úó FAILED'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guardrail 2: Engagement (Game Rounds per Player)\n",
      "==================================================\n",
      "Tolerance: -5.0% (max allowed degradation)\n",
      "\n",
      "Control mean:   52.46 rounds\n",
      "Treatment mean: 51.30 rounds\n",
      "\n",
      "Relative change:    -2.21%\n",
      "95% CI lower bound: -6.31%\n",
      "\n",
      "Result: ‚úó FAILED\n"
     ]
    }
   ],
   "source": [
    "# Guardrail 2: Engagement (must not degrade more than 5%)\n",
    "guardrail_engagement = guardrails.non_inferiority_test(\n",
    "    control=control_rounds,\n",
    "    treatment=treatment_rounds,\n",
    "    delta=-0.05,\n",
    "    metric_type='relative',\n",
    "    alpha=0.05\n",
    ")\n",
    "guardrail_engagement['metric_name'] = 'Engagement (Game Rounds)'\n",
    "\n",
    "print(\"Guardrail 2: Engagement (Game Rounds per Player)\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Tolerance: -5.0% (max allowed degradation)\")\n",
    "print(f\"\\nControl mean:   {guardrail_engagement['mean_control']:.2f} rounds\")\n",
    "print(f\"Treatment mean: {guardrail_engagement['mean_treatment']:.2f} rounds\")\n",
    "\n",
    "rel_change_eng = guardrail_engagement['difference'] / guardrail_engagement['mean_control']\n",
    "rel_ci_lower_eng = guardrail_engagement['ci_lower'] / guardrail_engagement['mean_control']\n",
    "\n",
    "print(f\"\\nRelative change:    {rel_change_eng:.2%}\")\n",
    "print(f\"95% CI lower bound: {rel_ci_lower_eng:.2%}\")\n",
    "print(f\"\\nResult: {'‚úì PASSED' if guardrail_engagement['passed'] else '‚úó FAILED'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: The Ship / Hold / Abandon Decision\n",
    "\n",
    "### üí° Interview Insight: The Decision Framework\n",
    "\n",
    "This is often the most important part of an interview discussion. Interviewers want to see how you synthesize statistical results into business decisions.\n",
    "\n",
    "**The Framework:**\n",
    "\n",
    "| Decision | Criteria |\n",
    "|----------|----------|\n",
    "| **SHIP** | Primary metric significant AND positive AND all guardrails pass |\n",
    "| **ABANDON** | Primary metric significant AND negative OR any guardrail fails |\n",
    "| **HOLD** | Primary metric not significant OR mixed signals |\n",
    "\n",
    "**Key Principle**: We don't ship on neutral results, and we don't ship if we're causing harm elsewhere.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "DECISION FRAMEWORK EVALUATION\n",
      "============================================================\n",
      "\n",
      "üéØ Primary Metric: 1-Day Retention\n",
      "   Significant: False\n",
      "   Positive:    False\n",
      "   Lift:        -1.32%\n",
      "\n",
      "üõ°Ô∏è  Guardrail Metrics:\n",
      "   Passed: 0 / 2\n",
      "   - 7-Day Retention: ‚úó FAILED\n",
      "   - Engagement:      ‚úó FAILED\n",
      "\n",
      "============================================================\n",
      ">>> FINAL DECISION: HOLD <<<\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Make final decision using the framework\n",
    "decision_result = guardrails.evaluate_guardrails(\n",
    "    primary_result={\n",
    "        'significant': retention_1d_result['significant'],\n",
    "        'relative_lift': retention_1d_result['relative_lift'],\n",
    "        'p_value': retention_1d_result['p_value']\n",
    "    },\n",
    "    guardrail_results=[guardrail_retention_7d, guardrail_engagement]\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"DECISION FRAMEWORK EVALUATION\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nüéØ Primary Metric: 1-Day Retention\")\n",
    "print(f\"   Significant: {decision_result['primary_significant']}\")\n",
    "print(f\"   Positive:    {decision_result['primary_positive']}\")\n",
    "print(f\"   Lift:        {retention_1d_result['relative_lift']:.2%}\")\n",
    "\n",
    "print(f\"\\nüõ°Ô∏è  Guardrail Metrics:\")\n",
    "print(f\"   Passed: {decision_result['guardrails_passed']} / {decision_result['guardrails_total']}\")\n",
    "print(f\"   - 7-Day Retention: {'‚úì PASSED' if guardrail_retention_7d['passed'] else '‚úó FAILED'}\")\n",
    "print(f\"   - Engagement:      {'‚úì PASSED' if guardrail_engagement['passed'] else '‚úó FAILED'}\")\n",
    "\n",
    "print(f\"\\n\" + \"=\" * 60)\n",
    "decision = decision_result['decision'].upper()\n",
    "print(f\">>> FINAL DECISION: {decision} <<<\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7: Interpreting the Decision (Connecting to Business)\n",
    "\n",
    "### üí° Interview Insight: Connecting Statistics to Business Impact\n",
    "\n",
    "The final step is translating your analysis into business terms. This is where judgment matters more than formulas.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "BUSINESS INTERPRETATION\n",
      "============================================================\n",
      "\n",
      "‚ö™ RECOMMENDATION: HOLD\n",
      "\n",
      "Why hold?\n",
      "  ‚Ä¢ Primary metric not statistically significant\n",
      "  ‚Ä¢ Observed -1.32% lift could be random noise\n",
      "\n",
      "Options:\n",
      "  1. Extend experiment duration for more data\n",
      "  2. Increase traffic allocation for faster results\n",
      "  3. Analyze subgroups (new vs. existing players)\n"
     ]
    }
   ],
   "source": [
    "# Business impact interpretation\n",
    "decision = decision_result['decision'].upper()\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"BUSINESS INTERPRETATION\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "if decision == 'SHIP':\n",
    "    print(\"\\n‚úÖ RECOMMENDATION: SHIP\")\n",
    "    print(\"\\nWhy ship?\")\n",
    "    print(f\"  ‚Ä¢ Primary metric improved by {retention_1d_result['relative_lift']:.2%}\")\n",
    "    print(f\"  ‚Ä¢ All guardrails passed\")\n",
    "    print(\"\\nBusiness impact (per 100,000 new players):\")\n",
    "    additional_returns = abs(retention_1d_result['absolute_lift']) * 100000\n",
    "    print(f\"  ‚Ä¢ Additional day-1 returns: {additional_returns:.0f} players\")\n",
    "    print(\"  ‚Ä¢ More engaged base ‚Üí more monetization opportunities\")\n",
    "    print(\"\\nNext steps:\")\n",
    "    print(\"  1. Roll out to 100% of players\")\n",
    "    print(\"  2. Monitor 7-day and 30-day retention post-launch\")\n",
    "    print(\"  3. Track revenue impact\")\n",
    "\n",
    "elif decision == 'ABANDON':\n",
    "    print(\"\\n‚ùå RECOMMENDATION: ABANDON\")\n",
    "    print(\"\\nWhy abandon?\")\n",
    "    if not decision_result['primary_positive']:\n",
    "        print(f\"  ‚Ä¢ Primary metric showed NEGATIVE impact ({retention_1d_result['relative_lift']:.2%})\")\n",
    "    if not guardrail_retention_7d['passed']:\n",
    "        print(f\"  ‚Ä¢ 7-day retention guardrail FAILED\")\n",
    "    if not guardrail_engagement['passed']:\n",
    "        print(f\"  ‚Ä¢ Engagement guardrail FAILED\")\n",
    "    print(\"\\nBusiness impact:\")\n",
    "    lost_returns = abs(retention_1d_result['absolute_lift']) * 100000\n",
    "    print(f\"  ‚Ä¢ Would lose ~{lost_returns:.0f} day-1 returns per 100K players\")\n",
    "    print(\"\\nLearnings:\")\n",
    "    print(\"  ‚Ä¢ Delaying the gate doesn't reduce frustration‚Äîit may increase it\")\n",
    "    print(\"  ‚Ä¢ Sunk cost: Players invested in 40 levels react worse to being stopped\")\n",
    "    print(\"\\nNext steps:\")\n",
    "    print(\"  1. Test alternative gate presentations (instead of positions)\")\n",
    "    print(\"  2. Consider gate at level 35 as a middle ground\")\n",
    "    print(\"  3. Analyze user feedback for qualitative insights\")\n",
    "\n",
    "else:  # HOLD\n",
    "    print(\"\\n‚ö™ RECOMMENDATION: HOLD\")\n",
    "    print(\"\\nWhy hold?\")\n",
    "    if not decision_result['primary_significant']:\n",
    "        print(f\"  ‚Ä¢ Primary metric not statistically significant\")\n",
    "        print(f\"  ‚Ä¢ Observed {retention_1d_result['relative_lift']:.2%} lift could be random noise\")\n",
    "    print(\"\\nOptions:\")\n",
    "    print(\"  1. Extend experiment duration for more data\")\n",
    "    print(\"  2. Increase traffic allocation for faster results\")\n",
    "    print(\"  3. Analyze subgroups (new vs. existing players)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary: The Complete Lifecycle\n",
    "\n",
    "We've walked through the full A/B testing lifecycle:\n",
    "\n",
    "| Phase | What We Did | Key Insight |\n",
    "|-------|-------------|-------------|\n",
    "| **1. Frame** | Articulated hypothesis with mechanism and risk | Hypotheses need reasoning, not just predictions |\n",
    "| **2. Metrics** | Chose primary + guardrails with trade-offs | Metric selection involves business judgment |\n",
    "| **3. Validate** | Two-stage SRM check | Don't analyze until you've validated |\n",
    "| **4. Analyze** | Z-tests + multiple testing correction | Statistics are just one piece |\n",
    "| **5. Decide** | Ship/Hold/Abandon with business context | Judgment > formulas |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéì Exercises for Practice\n",
    "\n",
    "### Exercise 1: Different Guardrail Thresholds\n",
    "What if we set a stricter guardrail (-0.5% instead of -1%) for 7-day retention? How does this change the decision?\n",
    "\n",
    "### Exercise 2: Segment Analysis\n",
    "Do the results differ for high-engagement players (>50 rounds) vs. low-engagement players?\n",
    "\n",
    "### Exercise 3: Interview Practice\n",
    "Write a 3-minute explanation of this experiment and its results as if presenting to a non-technical product manager. Focus on: what we learned, what we recommend, and what uncertainties remain.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 1: Stricter guardrail\n",
    "# Try running the non-inferiority test with delta=-0.005 (0.5%) instead of -0.01\n",
    "# Your code here:\n",
    "\n",
    "# guardrail_strict = guardrails.non_inferiority_test(\n",
    "#     control=control_retention_7d,\n",
    "#     treatment=treatment_retention_7d,\n",
    "#     delta=-0.005,  # Stricter threshold\n",
    "#     metric_type='relative',\n",
    "#     alpha=0.05\n",
    "# )\n",
    "# print(f\"Stricter guardrail passed: {guardrail_strict['passed']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 2: Segment analysis\n",
    "# Your code here:\n",
    "\n",
    "# high_engagement_control = control_df[control_df['sum_gamerounds'] > 50]['retention_1'].values\n",
    "# high_engagement_treatment = treatment_df[treatment_df['sum_gamerounds'] > 50]['retention_1'].values\n",
    "# \n",
    "# segment_result = frequentist.z_test_proportions(\n",
    "#     control=high_engagement_control,\n",
    "#     treatment=high_engagement_treatment,\n",
    "#     alpha=0.05\n",
    "# )\n",
    "# print(f\"High-engagement segment lift: {segment_result['relative_lift']:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Key Takeaways for Interviews\n",
    "\n",
    "1. **Lead with the lifecycle, not the math.** Start by framing the question and choosing metrics before touching any code.\n",
    "\n",
    "2. **Validate before you analyze.** SRM checks aren't optional‚Äîthey're the first line of defense against bad data.\n",
    "\n",
    "3. **Trade-offs are everywhere.** Articulating what you're optimizing vs. protecting shows business maturity.\n",
    "\n",
    "4. **Negative results are valuable.** An experiment that disproves your hypothesis is still a successful experiment.\n",
    "\n",
    "5. **Connect to business impact.** Translate statistical results into dollars, users, or concrete outcomes.\n",
    "\n",
    "6. **Know your uncertainty.** Strong candidates acknowledge what they don't know and suggest next steps.\n",
    "\n",
    "---\n",
    "\n",
    "**Next Notebook**: [02_criteo_advanced_techniques.ipynb](02_criteo_advanced_techniques.ipynb) - Advanced techniques for complex, real-world scenarios where assumptions break down and judgment matters more than formulas."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ab-testing (3.13.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

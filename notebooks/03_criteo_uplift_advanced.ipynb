{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Criteo Uplift Analysis: ML-Enhanced Experimentation\n",
    "\n",
    "**Scenario**: Ad tech company optimizing targeted campaigns\n",
    "\n",
    "**Business Question**: Who should we target to maximize incremental conversions?\n",
    "\n",
    "**Dataset**: 13.9M observations (use sample for faster execution)\n",
    "\n",
    "**Key Features**: 11 user characteristics for ML-enhanced variance reduction\n",
    "\n",
    "## üìö What You'll Learn\n",
    "\n",
    "1. ‚úÖ CUPAC (ML-enhanced CUPED with GradientBoosting)\n",
    "2. ‚úÖ X-Learner for heterogeneous treatment effects (HTE)\n",
    "3. ‚úÖ Sequential testing for early stopping\n",
    "4. ‚úÖ Large-scale data best practices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from ab_testing.data import loaders\n",
    "from ab_testing.pipelines.criteo_pipeline import run_criteo_analysis\n",
    "\n",
    "print(\"‚úÖ Ready to analyze Criteo data!\")\n",
    "print(\"\\n‚ö†Ô∏è NOTE: Full dataset is 13.9M rows. Using sample_frac=0.01 (1%) for faster execution.\")\n",
    "print(\"   This gives ~140K rows, which is still large enough for all techniques.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Load Data (1% Sample)\n",
    "\n",
    "For development/learning, we'll use 1% of the data (~140K rows).\n",
    "\n",
    "For production analysis, use larger samples or full dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load 1% sample (adjust sample_frac as needed)\n",
    "df = loaders.load_criteo_uplift(sample_frac=0.01)\n",
    "\n",
    "print(f\"Loaded {len(df):,} observations (1% sample)\")\n",
    "print(f\"\\nColumns: {df.columns.tolist()}\")\n",
    "display(df.head())\n",
    "\n",
    "print(f\"\\nTreatment split:\")\n",
    "print(df['treatment'].value_counts())\n",
    "\n",
    "print(f\"\\nOutcome rates:\")\n",
    "print(f\"Visit rate: {df['visit'].mean():.4%}\")\n",
    "print(f\"Conversion rate: {df['conversion'].mean():.4%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Run Complete Analysis\n",
    "\n",
    "**‚ö†Ô∏è This may take 2-5 minutes** due to ML model training (CUPAC, X-Learner).\n",
    "\n",
    "Progress will be shown during execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run with 1% sample (faster execution)\n",
    "results = run_criteo_analysis(sample_frac=0.01, verbose=False)\n",
    "\n",
    "print(f\"‚úÖ Analysis complete!\")\n",
    "print(f\"Available results: {list(results.keys())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: CUPAC vs CUPED Comparison\n",
    "\n",
    "### üìö The Difference\n",
    "\n",
    "**CUPED (Linear)**:\n",
    "- Uses 1 covariate\n",
    "- Linear adjustment: `Y_adj = Y - Œ∏ * (X - E[X])`\n",
    "- Typical: 20-40% variance reduction\n",
    "\n",
    "**CUPAC (ML-Enhanced)**:\n",
    "- Uses multiple features (11 in Criteo)\n",
    "- ML model (GradientBoosting): `Y_adj = Y - Y_pred`\n",
    "- Captures non-linear relationships\n",
    "- Typical: 30-60% variance reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cupac = results.get('cupac', {})\n",
    "\n",
    "if cupac:\n",
    "    print(\"=\" * 70)\n",
    "    print(\"CUPAC RESULTS\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    print(f\"\\nüìä Model Performance:\")\n",
    "    print(f\"   Model type: {cupac.get('model', 'N/A')}\")\n",
    "    print(f\"   Features used: {cupac.get('n_features', 11)}\")\n",
    "    print(f\"   Model R¬≤: {cupac.get('model_r2', 'N/A'):.4f}\")\n",
    "    \n",
    "    print(f\"\\nüìä Variance Reduction:\")\n",
    "    print(f\"   Variance reduction: {cupac.get('var_reduction', 0):.2%}\")\n",
    "    print(f\"   SE reduction: {cupac.get('se_reduction', 0):.2%}\")\n",
    "    \n",
    "    var_red = cupac.get('var_reduction', 0)\n",
    "    sample_equiv = 1 / (1 - var_red) if var_red < 1 else 1\n",
    "    \n",
    "    print(f\"\\nüí° PRACTICAL IMPACT:\")\n",
    "    print(f\"   - Equivalent to {sample_equiv:.1f}x more users\")\n",
    "    print(f\"   - Or run experiment {(1-var_red):.0%} as long\")\n",
    "    print(f\"   - Example: 4-week test ‚Üí {4*(1-var_red):.1f} weeks with CUPAC\")\n",
    "    \n",
    "    print(f\"\\nüè¢ When CUPAC Beats CUPED:\")\n",
    "    print(f\"   ‚úÖ Multiple features available (11+ features)\")\n",
    "    print(f\"   ‚úÖ Non-linear relationships (power users behave differently)\")\n",
    "    print(f\"   ‚úÖ Large dataset (n > 10K for ML training)\")\n",
    "    print(f\"   ‚úÖ Worth the complexity (30-60% vs 20-40% reduction)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Heterogeneous Treatment Effects (X-Learner)\n",
    "\n",
    "### üìö Why HTE Matters\n",
    "\n",
    "**Average Treatment Effect (ATE)**: Overall impact across all users\n",
    "\n",
    "**Problem**: Not everyone benefits equally!\n",
    "- Some users: +20% conversion (high uplift)\n",
    "- Some users: -5% conversion (negative effect)\n",
    "- Average: +5% (misleading!)\n",
    "\n",
    "**Solution**: Estimate individual-level treatment effects (CATE)\n",
    "- **CATE** = Conditional Average Treatment Effect\n",
    "- Enables targeting: Focus on high-uplift users\n",
    "- Example: \"Don't send promo to users who'd convert anyway\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hte = results.get('hte', {})\n",
    "\n",
    "if hte:\n",
    "    print(\"=\" * 70)\n",
    "    print(\"HETEROGENEOUS TREATMENT EFFECTS (X-Learner)\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    print(f\"\\nüìä CATE Distribution:\")\n",
    "    cate_values = hte.get('cate_estimates', [])\n",
    "    if len(cate_values) > 0:\n",
    "        print(f\"   Mean CATE: {np.mean(cate_values):.4f}\")\n",
    "        print(f\"   Std CATE: {np.std(cate_values):.4f}\")\n",
    "        print(f\"   Min CATE: {np.min(cate_values):.4f} (negative effect)\")\n",
    "        print(f\"   Max CATE: {np.max(cate_values):.4f} (high uplift)\")\n",
    "        \n",
    "        # Analyze subgroups\n",
    "        top_10pct = np.percentile(cate_values, 90)\n",
    "        bottom_10pct = np.percentile(cate_values, 10)\n",
    "        \n",
    "        print(f\"\\nüìä Subgroup Analysis:\")\n",
    "        print(f\"   Top 10% CATE threshold: {top_10pct:.4f}\")\n",
    "        print(f\"   Bottom 10% CATE threshold: {bottom_10pct:.4f}\")\n",
    "        print(f\"   Spread: {top_10pct - bottom_10pct:.4f}\")\n",
    "        \n",
    "        print(f\"\\nüí° TARGETING DECISION:\")\n",
    "        print(f\"   - Target top 10%: Expect {top_10pct:.2%} incremental lift\")\n",
    "        print(f\"   - Avoid bottom 10%: Negative effect ({bottom_10pct:.2%})\")\n",
    "        print(f\"   - Or use continuous score for dynamic targeting\")\n",
    "        \n",
    "        print(f\"\\nüè¢ Industry Applications:\")\n",
    "        print(f\"   - Netflix: Personalize which shows to promote per user\")\n",
    "        print(f\"   - Uber: Target promos to users with high incremental value\")\n",
    "        print(f\"   - E-commerce: Personalize discounts based on uplift\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Sequential Testing (Early Stopping)\n",
    "\n",
    "### üìö The Benefit\n",
    "\n",
    "**Traditional Approach**: Run experiment for fixed duration (e.g., 4 weeks)\n",
    "\n",
    "**Sequential Testing**: Check results at interim points, stop early if effect is clear\n",
    "\n",
    "**Average Savings**: 30-50% reduction in experiment duration\n",
    "\n",
    "**Key**: Properly control Type I error via alpha spending function (O'Brien-Fleming)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq = results.get('sequential', {})\n",
    "\n",
    "if seq:\n",
    "    print(\"=\" * 70)\n",
    "    print(\"SEQUENTIAL TESTING RESULTS\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    print(f\"\\nüìä Configuration:\")\n",
    "    print(f\"   Number of looks: {seq.get('n_looks', 5)}\")\n",
    "    print(f\"   Overall alpha: 0.05\")\n",
    "    print(f\"   Method: O'Brien-Fleming\")\n",
    "    \n",
    "    boundaries = seq.get('boundaries', [])\n",
    "    if boundaries:\n",
    "        print(f\"\\nüìä Alpha Spending at Each Look:\")\n",
    "        for i, bound in enumerate(boundaries, 1):\n",
    "            print(f\"   Look {i}: alpha = {bound:.6f}\")\n",
    "    \n",
    "    print(f\"\\nüí° HOW TO USE:\")\n",
    "    print(f\"   1. Pre-commit to analysis plan (e.g., check every week for 5 weeks)\")\n",
    "    print(f\"   2. At each look, compare p-value to boundary\")\n",
    "    print(f\"   3. If p < boundary ‚Üí STOP, effect is significant\")\n",
    "    print(f\"   4. If p ‚â• boundary ‚Üí CONTINUE to next look\")\n",
    "    print(f\"   5. At final look, use standard alpha=0.05\")\n",
    "    \n",
    "    print(f\"\\nüè¢ Industry Impact:\")\n",
    "    print(f\"   - Average 30-50% shorter experiments\")\n",
    "    print(f\"   - Saves money and increases velocity\")\n",
    "    print(f\"   - Trade-off: Slight power loss if run to end\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚úÖ Key Takeaways\n",
    "\n",
    "1. **CUPAC > CUPED** when you have rich features (11+) and large samples (n > 10K)\n",
    "2. **HTE enables targeting** - \"Who benefits most?\" is the modern question\n",
    "3. **X-Learner estimates individual effects** - Enables personalization decisions\n",
    "4. **Sequential testing reduces duration** - Stop early when possible (30-50% faster)\n",
    "5. **Large-scale data requires sampling** - Use sample_frac for development\n",
    "\n",
    "## üî¨ Try These Experiments\n",
    "\n",
    "1. **Different sample sizes**: Try 0.001, 0.01, 0.10 - how do results change?\n",
    "2. **ML model comparison**: CUPAC with RandomForest vs GradientBoosting\n",
    "3. **Subgroup targeting**: Calculate ROI of targeting top 10% vs top 50%\n",
    "4. **Sequential boundaries**: Try different # of looks (3, 5, 10)\n",
    "5. **Feature importance**: Which features matter most for CATE?\n",
    "\n",
    "## üìö Further Reading\n",
    "\n",
    "**Papers**:\n",
    "- Athey & Imbens (2016): \"Recursive partitioning for heterogeneous causal effects\"\n",
    "- K√ºnzel et al. (2019): \"Metalearners for estimating heterogeneous treatment effects\"\n",
    "\n",
    "**Industry Blogs**:\n",
    "- [DoorDash: CUPAC](https://careersatdoordash.com/blog/improving-experimental-power-through-control-using-predictions-as-covariate-cupac/)\n",
    "- [Uber: Causal ML](https://www.uber.com/blog/causal-inference-at-uber/)\n",
    "- [Netflix: Experimentation at Scale](https://netflixtechblog.com/experimentation-at-netflix-6ab9a47e7caa)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

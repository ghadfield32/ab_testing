{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A/B Testing Reference Guide\n",
    "## Quick Reference for Concepts, Techniques, and Interview Prep\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ¯ How to Use This Guide\n",
    "\n",
    "This notebook serves as a **quick reference** for all concepts covered in the masterclass series. Use it to:\n",
    "\n",
    "1. **Review before interviews** - Refresh key concepts and decision frameworks\n",
    "2. **Look up techniques** - Find when to use what method\n",
    "3. **Check code patterns** - Copy-paste templates for common tasks\n",
    "4. **Understand trade-offs** - Quick comparison tables\n",
    "\n",
    "### The A/B Testing Lifecycle (Your Mental Model)\n",
    "\n",
    "In interviews, always anchor your answers to this lifecycle:\n",
    "\n",
    "```\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚                    THE EXPERIMENTATION LIFECYCLE                â”‚\n",
    "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
    "â”‚                                                                 â”‚\n",
    "â”‚  1. FRAME THE QUESTION                                          â”‚\n",
    "â”‚     â€¢ What business problem are we solving?                     â”‚\n",
    "â”‚     â€¢ What's our hypothesis (with mechanism and risks)?         â”‚\n",
    "â”‚                                                                 â”‚\n",
    "â”‚  2. DESIGN THE EXPERIMENT                                       â”‚\n",
    "â”‚     â€¢ Choose metrics (primary + guardrails)                     â”‚\n",
    "â”‚     â€¢ Calculate sample size (power analysis)                    â”‚\n",
    "â”‚     â€¢ Define success criteria upfront                           â”‚\n",
    "â”‚                                                                 â”‚\n",
    "â”‚  3. VALIDATE THE DATA                                           â”‚\n",
    "â”‚     â€¢ Data quality checks                                       â”‚\n",
    "â”‚     â€¢ SRM check (did randomization work?)                       â”‚\n",
    "â”‚     â€¢ Classify: RCT vs. observational                           â”‚\n",
    "â”‚                                                                 â”‚\n",
    "â”‚  4. ANALYZE RESULTS                                             â”‚\n",
    "â”‚     â€¢ Primary metric test                                       â”‚\n",
    "â”‚     â€¢ Variance reduction (CUPED/CUPAC)                          â”‚\n",
    "â”‚     â€¢ Multiple testing correction                               â”‚\n",
    "â”‚     â€¢ Heterogeneous effects (if relevant)                       â”‚\n",
    "â”‚                                                                 â”‚\n",
    "â”‚  5. INTERPRET & DECIDE                                          â”‚\n",
    "â”‚     â€¢ Guardrail evaluation                                      â”‚\n",
    "â”‚     â€¢ Novelty effect check                                      â”‚\n",
    "â”‚     â€¢ Business impact calculation                               â”‚\n",
    "â”‚     â€¢ Ship / Hold / Abandon decision                            â”‚\n",
    "â”‚                                                                 â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "```\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Dataset Classification\n",
    "\n",
    "### When to Use Which Classification\n",
    "\n",
    "| Allocation | Classification | SRM Action | Causal Claims |\n",
    "|------------|----------------|------------|---------------|\n",
    "| 40-60% | **RCT** | Compare to expected ratio | Full causal inference |\n",
    "| 10-40% or 60-90% | **Designed Imbalance** | Compare to intended ratio | Full causal inference |\n",
    "| <10% or >90% | **Observational** | Note, don't gate | Associational only |\n",
    "\n",
    "### Code Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_dataset(treatment_ratio):\n",
    "    \"\"\"Classify dataset based on treatment allocation.\"\"\"\n",
    "    if 0.4 <= treatment_ratio <= 0.6:\n",
    "        return 'RCT', 'Compare to expected ratio'\n",
    "    elif 0.1 <= treatment_ratio <= 0.9:\n",
    "        return 'DESIGNED_IMBALANCE', 'Compare to intended ratio'\n",
    "    else:\n",
    "        return 'OBSERVATIONAL', 'Causal claims limited'\n",
    "\n",
    "# Usage:\n",
    "# data_type, action = classify_dataset(treatment_count / total_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. SRM (Sample Ratio Mismatch)\n",
    "\n",
    "### Two-Stage Gating Framework\n",
    "\n",
    "```\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚                    TWO-STAGE SRM GATING                     â”‚\n",
    "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
    "â”‚                                                             â”‚\n",
    "â”‚  Stage 1: STATISTICAL SIGNIFICANCE                          â”‚\n",
    "â”‚     â€¢ Chi-square test: p < 0.01?                            â”‚\n",
    "â”‚     â€¢ If NO â†’ Pass, proceed to analysis                     â”‚\n",
    "â”‚     â€¢ If YES â†’ Check Stage 2                                â”‚\n",
    "â”‚                                                             â”‚\n",
    "â”‚  Stage 2: PRACTICAL SIGNIFICANCE                            â”‚\n",
    "â”‚     â€¢ Deviation > 1 percentage point?                       â”‚\n",
    "â”‚     â€¢ If NO â†’ Warning only, proceed with caution            â”‚\n",
    "â”‚     â€¢ If YES â†’ HARD GATE, stop analysis                     â”‚\n",
    "â”‚                                                             â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "```\n",
    "\n",
    "### Code Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "from ab_testing.core import randomization\n\ndef check_srm_with_gating(n_control, n_treatment, expected_ratio=[0.5, 0.5], is_rct=True):\n    \"\"\"Two-stage SRM check with gating logic.\"\"\"\n    \n    srm_result = randomization.srm_check(\n        n_control=n_control,\n        n_treatment=n_treatment,\n        expected_ratio=expected_ratio,\n        alpha=0.01\n    )\n    \n    # Stage 1: Statistical significance\n    stat_sig = srm_result['srm_detected']\n    \n    # Stage 2: Practical significance (>1 percentage point)\n    deviation = srm_result['max_pp_deviation']\n    practical_sig = srm_result['practical_significant']\n    \n    # Decision logic\n    if is_rct and srm_result['srm_severe']:\n        return 'HARD_GATE', 'Stop analysis, investigate randomization'\n    elif srm_result['srm_warning']:\n        return 'WARNING', 'Statistical but not practical significance, proceed with caution'\n    else:\n        return 'PASS', 'Randomization appears correct'\n\n# Usage:\n# status, message = check_srm_with_gating(control_n, treatment_n, expected_ratio=[0.5, 0.5])"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ’¡ Interview Question: SRM Interpretation\n",
    "\n",
    "**Q**: *\"The SRM check is statistically significant but the deviation is only 0.3%. Should we stop?\"*\n",
    "\n",
    "**A**: *\"No. With large samples, even tiny deviations become statistically significant. A 0.3% deviation (49.7% vs 50.3%) won't meaningfully bias our treatment effect estimates. We'd only stop if the deviation were large enough to indicate a systematic problemâ€”typically >1 percentage point. This is statistical but not practical significance.\"*\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Statistical Tests\n",
    "\n",
    "### When to Use Which Test\n",
    "\n",
    "| Outcome Type | Metric Example | Test | Module Function |\n",
    "|--------------|----------------|------|------------------|\n",
    "| Binary | Conversion, Retention | Z-test for proportions | `frequentist.z_test_proportions()` |\n",
    "| Continuous | Revenue, Time on site | T-test or Z-test | `frequentist.t_test()` |\n",
    "| Ratio | Revenue/user, CTR | Delta method | `ratio_metrics.ratio_metric_test()` |\n",
    "| Count | Purchases, Clicks | Poisson or NB | Depends on overdispersion |\n",
    "\n",
    "### Code Templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ab_testing.core import frequentist\n",
    "from ab_testing.advanced import ratio_metrics\n",
    "\n",
    "# Binary outcome (conversion, retention)\n",
    "def test_binary_metric(control, treatment, alpha=0.05):\n",
    "    \"\"\"Z-test for binary outcomes.\"\"\"\n",
    "    return frequentist.z_test_proportions(\n",
    "        control=control,\n",
    "        treatment=treatment,\n",
    "        alpha=alpha\n",
    "    )\n",
    "\n",
    "# Ratio metric (revenue per user, clicks per session)\n",
    "def test_ratio_metric(control_num, control_denom, treatment_num, treatment_denom, alpha=0.05):\n",
    "    \"\"\"Delta method for ratio metrics.\"\"\"\n",
    "    return ratio_metrics.ratio_metric_test(\n",
    "        control_num=control_num,\n",
    "        control_denom=control_denom,\n",
    "        treatment_num=treatment_num,\n",
    "        treatment_denom=treatment_denom,\n",
    "        alpha=alpha\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. Multiple Testing Correction\n",
    "\n",
    "### When to Use Which Method\n",
    "\n",
    "| Method | Controls | When to Use |\n",
    "|--------|----------|-------------|\n",
    "| **None** | - | Single metric |\n",
    "| **Bonferroni** | FWER | Very conservative; high cost of false positives |\n",
    "| **Benjamini-Hochberg** | FDR | Standard choice for 2-20 metrics |\n",
    "| **Holm** | FWER | Less conservative than Bonferroni |\n",
    "\n",
    "### Decision Framework\n",
    "\n",
    "- **1 metric**: No correction needed\n",
    "- **2-5 metrics**: Benjamini-Hochberg (FDR control)\n",
    "- **6-20 metrics**: Benjamini-Hochberg\n",
    "- **20+ metrics**: Consider grouping or hierarchical testing\n",
    "\n",
    "### Code Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ab_testing.advanced import multiple_testing\n",
    "\n",
    "def correct_multiple_tests(p_values, method='benjamini-hochberg', alpha=0.05):\n",
    "    \"\"\"Apply multiple testing correction.\"\"\"\n",
    "    if method == 'benjamini-hochberg':\n",
    "        return multiple_testing.benjamini_hochberg(p_values=p_values, alpha=alpha)\n",
    "    elif method == 'bonferroni':\n",
    "        adjusted = [min(p * len(p_values), 1.0) for p in p_values]\n",
    "        return {'adjusted_p_values': adjusted, 'reject_null': [p < alpha for p in adjusted]}\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown method: {method}\")\n",
    "\n",
    "# Usage:\n",
    "# result = correct_multiple_tests([0.03, 0.08, 0.001], method='benjamini-hochberg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ’¡ Interview Question: Multiple Testing\n",
    "\n",
    "**Q**: *\"We're testing 5 metrics. Do we need to correct for multiple testing?\"*\n",
    "\n",
    "**A**: *\"Yes. Testing 5 metrics at Î±=0.05 gives us a 1-(0.95)^5 â‰ˆ 23% chance of at least one false positive. I'd use Benjamini-Hochberg to control the False Discovery Rateâ€”it's less conservative than Bonferroni while still protecting against inflated error rates. The key distinction: BH controls the expected proportion of false discoveries among rejections, while Bonferroni controls the probability of any false positive.\"*\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Variance Reduction\n",
    "\n",
    "### CUPED vs. CUPAC Comparison\n",
    "\n",
    "| Aspect | CUPED | CUPAC |\n",
    "|--------|-------|-------|\n",
    "| **Adjustment** | Linear | ML model |\n",
    "| **Covariates** | Single (pre-experiment metric) | Multiple |\n",
    "| **Complexity** | Low | High |\n",
    "| **Data requirement** | Small OK | Large needed |\n",
    "| **Variance reduction** | ~30% typical | ~40%+ typical |\n",
    "| **When to use** | Default choice | Rich covariates, large samples |\n",
    "\n",
    "### Code Templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ab_testing.variance_reduction import cuped, cupac\n",
    "\n",
    "# CUPED (linear adjustment with pre-experiment metric)\n",
    "def run_cuped(y, treatment, x_pre, alpha=0.05):\n",
    "    \"\"\"CUPED variance reduction.\"\"\"\n",
    "    return cuped.cuped_ab_test(\n",
    "        y=y,\n",
    "        treatment=treatment,\n",
    "        x_pre=x_pre,\n",
    "        alpha=alpha\n",
    "    )\n",
    "\n",
    "# CUPAC (ML-enhanced variance reduction)\n",
    "def run_cupac(y, treatment, X, alpha=0.05):\n",
    "    \"\"\"CUPAC variance reduction with ML.\"\"\"\n",
    "    return cupac.cupac_ab_test(\n",
    "        y=y,\n",
    "        treatment=treatment,\n",
    "        X=X,\n",
    "        alpha=alpha\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ’¡ Interview Question: Variance Reduction\n",
    "\n",
    "**Q**: *\"When would you use CUPAC instead of CUPED?\"*\n",
    "\n",
    "**A**: *\"CUPAC shines when you have large samples (100K+) and rich covariate data with non-linear relationships. For example, at Netflix, they use CUPAC because they have billions of user features. CUPED is simpler and works well with just a pre-experiment measure of the outcome. If I have limited features or smaller samples, CUPED is usually sufficient and more interpretable. The key is whether the added complexity of ML provides meaningful variance reduction.\"*\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Heterogeneous Treatment Effects (HTE)\n",
    "\n",
    "### When to Analyze HTE\n",
    "\n",
    "| Scenario | Analyze HTE? | Why |\n",
    "|----------|--------------|-----|\n",
    "| Personalization decision | Yes | Need to know who benefits |\n",
    "| Targeting decision | Yes | Optimize ad spend |\n",
    "| Simple ship/no-ship | Maybe | If concerned about harm to segments |\n",
    "| Small sample | No | Insufficient power for subgroups |\n",
    "\n",
    "### Code Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ab_testing.advanced import hte\n",
    "import numpy as np\n",
    "\n",
    "def analyze_heterogeneity(X, treatment, y):\n",
    "    \"\"\"Analyze heterogeneous treatment effects using X-Learner.\"\"\"\n",
    "    \n",
    "    # Fit X-Learner\n",
    "    xlearner = hte.XLearner()\n",
    "    xlearner.fit(X=X, treatment=treatment, y=y)\n",
    "    \n",
    "    # Get individual treatment effects\n",
    "    cate = xlearner.predict(X)\n",
    "    \n",
    "    # Summary statistics\n",
    "    return {\n",
    "        'mean_cate': np.mean(cate),\n",
    "        'std_cate': np.std(cate),\n",
    "        'pct_positive': (cate > 0).mean(),\n",
    "        'pct_negative': (cate < 0).mean(),\n",
    "        'cate_estimates': cate\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ’¡ Interview Question: HTE Interpretation\n",
    "\n",
    "**Q**: *\"The ATE is +5%, but 30% of users show negative effects. What do you recommend?\"*\n",
    "\n",
    "**A**: *\"This is a judgment call with no single correct answer. I'd consider: (1) Can we reliably identify who benefits vs. who's harmed? (2) What's the cost of targeting vs. broad rollout? (3) How severe is the harm to the 30%? If we can target accurately and it's operationally feasible, I'd recommend targeting only positive responders. If targeting is impractical, we need to weigh aggregate benefit against harm to a minority. I'd also investigate WHY some users are harmedâ€”there might be a fixable product issue.\"*\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Sequential Testing\n",
    "\n",
    "### When to Use Sequential Testing\n",
    "\n",
    "| Scenario | Use Sequential? | Boundary |\n",
    "|----------|-----------------|----------|\n",
    "| Long experiment, want early stopping | Yes | O'Brien-Fleming |\n",
    "| High-stakes, need flexibility | Yes | Group sequential |\n",
    "| Short experiment, will wait | No | Fixed sample |\n",
    "| Need maximum power | No | Fixed sample |\n",
    "\n",
    "### Code Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ab_testing.advanced import sequential\n",
    "\n",
    "def get_sequential_boundaries(n_looks=5, alpha=0.05):\n",
    "    \"\"\"Generate O'Brien-Fleming boundaries for sequential testing.\"\"\"\n",
    "    return sequential.obrien_fleming_boundaries(\n",
    "        n_looks=n_looks,\n",
    "        alpha=alpha,\n",
    "        one_sided=False\n",
    "    )\n",
    "\n",
    "def check_sequential_decision(z_statistic, look_number, boundaries):\n",
    "    \"\"\"Check if we can stop at current interim analysis.\"\"\"\n",
    "    boundary = boundaries['z_boundaries'][look_number - 1]\n",
    "    \n",
    "    if abs(z_statistic) > boundary:\n",
    "        if z_statistic > 0:\n",
    "            return 'STOP_POSITIVE', f'Z={z_statistic:.2f} > {boundary:.2f}'\n",
    "        else:\n",
    "            return 'STOP_NEGATIVE', f'Z={z_statistic:.2f} < -{boundary:.2f}'\n",
    "    else:\n",
    "        return 'CONTINUE', f'Z={z_statistic:.2f} within Â±{boundary:.2f}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 8. Guardrails\n",
    "\n",
    "### Guardrail Threshold Guidelines\n",
    "\n",
    "| Metric Type | Typical Tolerance | Rationale |\n",
    "|-------------|-------------------|------------|\n",
    "| Revenue | -2% to -5% | High business impact |\n",
    "| Retention | -1% to -2% | Leading indicator |\n",
    "| Engagement | -5% to -10% | More tolerant |\n",
    "| Load time | +10% to +20% | Technical |\n",
    "\n",
    "### Code Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ab_testing.diagnostics import guardrails\n",
    "\n",
    "def check_guardrail(control, treatment, metric_name, delta, metric_type='relative'):\n",
    "    \"\"\"Run non-inferiority test for guardrail metric.\"\"\"\n",
    "    result = guardrails.non_inferiority_test(\n",
    "        control=control,\n",
    "        treatment=treatment,\n",
    "        delta=delta,  # e.g., -0.02 for 2% max degradation\n",
    "        metric_type=metric_type,\n",
    "        alpha=0.05\n",
    "    )\n",
    "    result['metric_name'] = metric_name\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 9. Decision Framework\n",
    "\n",
    "### Ship / Hold / Abandon Logic\n",
    "\n",
    "```\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚                     DECISION FRAMEWORK                          â”‚\n",
    "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
    "â”‚                                                                 â”‚\n",
    "â”‚  âœ… SHIP if:                                                    â”‚\n",
    "â”‚     â€¢ Primary metric significant AND positive                   â”‚\n",
    "â”‚     â€¢ ALL guardrails pass                                       â”‚\n",
    "â”‚     â€¢ No severe novelty effect (or acceptable)                  â”‚\n",
    "â”‚     â€¢ Business impact justifies implementation                  â”‚\n",
    "â”‚                                                                 â”‚\n",
    "â”‚  âŒ ABANDON if:                                                 â”‚\n",
    "â”‚     â€¢ Primary metric significant AND negative                   â”‚\n",
    "â”‚     â€¢ ANY guardrail fails                                       â”‚\n",
    "â”‚     â€¢ Severe SRM in RCT                                         â”‚\n",
    "â”‚                                                                 â”‚\n",
    "â”‚  âšª HOLD if:                                                    â”‚\n",
    "â”‚     â€¢ Primary metric not significant                            â”‚\n",
    "â”‚     â€¢ Mixed signals (some positive, some concerning)            â”‚\n",
    "â”‚     â€¢ Novelty detected, need holdout to verify                  â”‚\n",
    "â”‚     â€¢ Observational data, need proper RCT                       â”‚\n",
    "â”‚                                                                 â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "```\n",
    "\n",
    "### Code Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_decision(primary_result, guardrail_results, data_type='RCT'):\n",
    "    \"\"\"Make ship/hold/abandon decision.\"\"\"\n",
    "    \n",
    "    primary_sig = primary_result.get('significant', False)\n",
    "    primary_positive = primary_result.get('relative_lift', 0) > 0\n",
    "    all_guardrails_pass = all(g.get('passed', True) for g in guardrail_results)\n",
    "    \n",
    "    # Observational data gets special treatment\n",
    "    if data_type == 'OBSERVATIONAL':\n",
    "        return 'HOLD', 'Observational data - causal claims limited, consider RCT'\n",
    "    \n",
    "    # Decision logic\n",
    "    if primary_sig and not primary_positive:\n",
    "        return 'ABANDON', 'Primary metric significantly negative'\n",
    "    elif not all_guardrails_pass:\n",
    "        return 'ABANDON', 'One or more guardrails failed'\n",
    "    elif primary_sig and primary_positive and all_guardrails_pass:\n",
    "        return 'SHIP', 'Primary positive, all guardrails pass'\n",
    "    else:\n",
    "        return 'HOLD', 'Primary not significant or mixed signals'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 10. Business Impact Formulas\n",
    "\n",
    "### Key Calculations\n",
    "\n",
    "| Metric | Formula |\n",
    "|--------|----------|\n",
    "| Monthly impact | `visitors Ã— lift Ã— value_per_conversion` |\n",
    "| Annual impact | `monthly_impact Ã— 12` |\n",
    "| ROI | `(annual_impact - cost) / cost` |\n",
    "| Break-even lift | `cost / (visitors Ã— value Ã— 12)` |\n",
    "| NNT | `1 / absolute_lift` |\n",
    "\n",
    "### Code Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_business_impact(baseline_rate, lift, monthly_visitors, value_per_conversion, implementation_cost):\n",
    "    \"\"\"Calculate business impact metrics.\"\"\"\n",
    "    \n",
    "    # Current state\n",
    "    current_conversions = monthly_visitors * baseline_rate\n",
    "    current_revenue = current_conversions * value_per_conversion\n",
    "    \n",
    "    # New state\n",
    "    new_rate = baseline_rate * (1 + lift)\n",
    "    new_conversions = monthly_visitors * new_rate\n",
    "    new_revenue = new_conversions * value_per_conversion\n",
    "    \n",
    "    # Impact\n",
    "    monthly_impact = new_revenue - current_revenue\n",
    "    annual_impact = monthly_impact * 12\n",
    "    roi = (annual_impact - implementation_cost) / implementation_cost if implementation_cost > 0 else float('inf')\n",
    "    \n",
    "    return {\n",
    "        'monthly_impact': monthly_impact,\n",
    "        'annual_impact': annual_impact,\n",
    "        'roi': roi,\n",
    "        'additional_conversions_monthly': new_conversions - current_conversions\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 11. Module Reference\n",
    "\n",
    "### Quick Lookup Table\n",
    "\n",
    "| Task | Module | Function |\n",
    "|------|--------|----------|\n",
    "| SRM check | `ab_testing.core.randomization` | `srm_check()` |\n",
    "| Power analysis | `ab_testing.core.power` | `power_analysis_summary()` |\n",
    "| Z-test (proportions) | `ab_testing.core.frequentist` | `z_test_proportions()` |\n",
    "| T-test | `ab_testing.core.frequentist` | `t_test()` |\n",
    "| CUPED | `ab_testing.variance_reduction.cuped` | `cuped_ab_test()` |\n",
    "| CUPAC | `ab_testing.variance_reduction.cupac` | `cupac_ab_test()` |\n",
    "| Multiple testing | `ab_testing.advanced.multiple_testing` | `benjamini_hochberg()` |\n",
    "| Ratio metrics | `ab_testing.advanced.ratio_metrics` | `ratio_metric_test()` |\n",
    "| HTE (X-Learner) | `ab_testing.advanced.hte` | `XLearner` |\n",
    "| Sequential testing | `ab_testing.advanced.sequential` | `obrien_fleming_boundaries()` |\n",
    "| Guardrails | `ab_testing.diagnostics.guardrails` | `non_inferiority_test()` |\n",
    "| Decision | `ab_testing.diagnostics.guardrails` | `evaluate_guardrails()` |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Common Interview Questions\n",
    "\n",
    "### Quick Answers\n",
    "\n",
    "| Question | Key Points |\n",
    "|----------|------------|\n",
    "| *\"Walk me through how you'd design an A/B test\"* | Frame hypothesis â†’ Choose metrics â†’ Power analysis â†’ Define success criteria â†’ Run â†’ Validate â†’ Analyze â†’ Decide |\n",
    "| *\"What's the difference between statistical and practical significance?\"* | Statistical: unlikely due to chance. Practical: large enough to matter for business. Need both for action. |\n",
    "| *\"How do you handle multiple testing?\"* | BH for FDR control with 2-20 metrics. Bonferroni if false positives very costly. None for single metric. |\n",
    "| *\"What would make you not trust an A/B test result?\"* | SRM failure, data quality issues, novelty effects, observational data, underpowered test. |\n",
    "| *\"The test isn't significant. What do you conclude?\"* | Check power/MDE first. Not significant â‰  no effect. Could lack power to detect. |\n",
    "| *\"Stakeholders want to peek at results daily. Is that okay?\"* | Not with fixed-sample tests (inflates error). Use sequential testing with O'Brien-Fleming boundaries. |\n",
    "| *\"How do you translate results to business impact?\"* | Convert lift to revenue using visitors Ã— lift Ã— value. Include CI for uncertainty range. |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Industry Best Practices Summary\n",
    "\n",
    "### By Company\n",
    "\n",
    "| Company | Notable Practice |\n",
    "|---------|------------------|\n",
    "| **Microsoft** | Automated SRM checks, blocks analysis on failure |\n",
    "| **Netflix** | CUPAC standard, 40%+ variance reduction |\n",
    "| **Booking.com** | Stricter SRM alpha (0.001), conservative approach |\n",
    "| **Uber** | X-Learner for personalized pricing |\n",
    "| **Spotify** | CUPED as baseline, ~30% average reduction |\n",
    "| **LinkedIn** | O'Brien-Fleming for sequential testing |\n",
    "| **Zynga/King** | 2-4 week minimum for game changes |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Takeaways: The Mental Model\n",
    "\n",
    "### What Separates Strong Candidates\n",
    "\n",
    "1. **Lead with the lifecycle, not the math.**\n",
    "   - Start with framing and metrics, not formulas.\n",
    "\n",
    "2. **Validate before you analyze.**\n",
    "   - Data quality and SRM come first.\n",
    "\n",
    "3. **Articulate trade-offs.**\n",
    "   - Every decision has pros and cons. Name them.\n",
    "\n",
    "4. **Connect to business impact.**\n",
    "   - P-values don't pay salariesâ€”revenue does.\n",
    "\n",
    "5. **Acknowledge uncertainty.**\n",
    "   - Use confidence intervals. Know what you don't know.\n",
    "\n",
    "6. **Know when to use advanced techniques.**\n",
    "   - CUPAC, HTE, sequential testing are tools, not goals.\n",
    "\n",
    "7. **Judgment > formulas.**\n",
    "   - The hardest part isn't the mathâ€”it's the decision.\n",
    "\n",
    "---\n",
    "\n",
    "**This is your foundation. The notebooks provide the depth. Use both together.**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
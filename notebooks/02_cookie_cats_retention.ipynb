{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cookie Cats Retention Analysis: Multiple Metrics & Product Trade-offs\n",
    "\n",
    "**Scenario**: Mobile game testing gate placement (level 30 vs level 40)\n",
    "\n",
    "**Business Question**: Does moving the gate improve retention?\n",
    "\n",
    "**Metrics**: 1-day retention, 7-day retention, rounds played per player\n",
    "\n",
    "**Dataset**: 90,189 players\n",
    "\n",
    "## üìö What You'll Learn\n",
    "\n",
    "1. ‚úÖ Testing multiple outcomes simultaneously (1d + 7d retention)\n",
    "2. ‚úÖ Multiple testing correction (Bonferroni vs Benjamini-Hochberg)\n",
    "3. ‚úÖ Ratio metrics with delta method\n",
    "4. ‚úÖ Product trade-off decisions (what if metrics conflict?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from ab_testing.data import loaders\n",
    "from ab_testing.pipelines.cookie_cats_pipeline import run_cookie_cats_analysis\n",
    "\n",
    "print(\"‚úÖ Ready to analyze Cookie Cats data!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = loaders.load_cookie_cats()\n",
    "print(f\"Loaded {len(df):,} players\")\n",
    "display(df.head())\n",
    "\n",
    "print(f\"\\nGroup split:\")\n",
    "print(df['version'].value_counts())\n",
    "\n",
    "print(f\"\\nRetention rates by group:\")\n",
    "retention = df.groupby('version')[['retention_1', 'retention_7']].mean()\n",
    "display(retention)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Run Complete Analysis\n",
    "\n",
    "This pipeline tests BOTH retention metrics and applies multiple testing correction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = run_cookie_cats_analysis(sample_frac=1.0, verbose=False)\n",
    "print(f\"‚úÖ Analysis complete!\")\n",
    "print(f\"Available results: {list(results.keys())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Multiple Testing Problem\n",
    "\n",
    "### üìö The Challenge\n",
    "\n",
    "When testing **k metrics** at alpha=0.05:\n",
    "- **Single test**: 5% false positive rate\n",
    "- **2 tests**: ~10% false positive rate (1 - 0.95¬≤)\n",
    "- **5 tests**: ~23% false positive rate\n",
    "- **10 tests**: ~40% false positive rate!\n",
    "\n",
    "**Solution**: Multiple testing correction to control family-wise error rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"1-DAY RETENTION TEST\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "ret1d = results['retention_1d']\n",
    "print(f\"Control: {ret1d['p_control']:.4%}\")\n",
    "print(f\"Treatment: {ret1d['p_treatment']:.4%}\")\n",
    "print(f\"Lift: {ret1d['relative_lift']:.2%}\")\n",
    "print(f\"P-value: {ret1d['p_value']:.6f}\")\n",
    "print(f\"Significant: {ret1d['significant']}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"7-DAY RETENTION TEST\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "ret7d = results['retention_7d']\n",
    "print(f\"Control: {ret7d['p_control']:.4%}\")\n",
    "print(f\"Treatment: {ret7d['p_treatment']:.4%}\")\n",
    "print(f\"Lift: {ret7d['relative_lift']:.2%}\")\n",
    "print(f\"P-value: {ret7d['p_value']:.6f}\")\n",
    "print(f\"Significant: {ret7d['significant']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple Testing Correction Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mt = results.get('multiple_testing', {})\n",
    "\n",
    "if mt:\n",
    "    comparison = pd.DataFrame({\n",
    "        'Metric': ['1-day retention', '7-day retention'],\n",
    "        'Original P-value': [\n",
    "            f\"{ret1d['p_value']:.6f}\",\n",
    "            f\"{ret7d['p_value']:.6f}\"\n",
    "        ],\n",
    "        'Bonferroni Threshold': [\n",
    "            f\"{0.05/2:.4f}\",\n",
    "            f\"{0.05/2:.4f}\"\n",
    "        ],\n",
    "        'Bonferroni Significant': [\n",
    "            '‚úÖ' if ret1d['p_value'] < 0.025 else '‚ùå',\n",
    "            '‚úÖ' if ret7d['p_value'] < 0.025 else '‚ùå'\n",
    "        ],\n",
    "        'BH-FDR Significant': [\n",
    "            '‚úÖ' if mt.get('bh_significant', [False, False])[0] else '‚ùå',\n",
    "            '‚úÖ' if mt.get('bh_significant', [False, False])[1] else '‚ùå'\n",
    "        ]\n",
    "    })\n",
    "    \n",
    "    display(comparison)\n",
    "    \n",
    "    print(f\"\\nüí° KEY INSIGHT:\")\n",
    "    print(f\"   - Bonferroni: More conservative (higher bar for significance)\")\n",
    "    print(f\"   - BH-FDR: More power (better at detecting real effects)\")\n",
    "    print(f\"   - For k=2 metrics, Bonferroni is reasonable\")\n",
    "    print(f\"   - For k>5 metrics, consider BH-FDR\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Decision Scenarios\n",
    "\n",
    "What if metrics conflict?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"DECISION SCENARIOS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "scenarios = pd.DataFrame({\n",
    "    'Scenario': [\n",
    "        'Both improve',\n",
    "        'Both worsen',\n",
    "        '1d improves, 7d worsens',\n",
    "        '1d worsens, 7d improves',\n",
    "        'Neither significant'\n",
    "    ],\n",
    "    'Decision': [\n",
    "        '‚úÖ SHIP',\n",
    "        '‚ùå ABANDON',\n",
    "        'ü§î DEPENDS (short-term gain, long-term loss)',\n",
    "        '‚úÖ SHIP (long-term matters more)',\n",
    "        '‚è∏Ô∏è HOLD (extend test or abandon)'\n",
    "    ],\n",
    "    'Rationale': [\n",
    "        'Clear winner across all timeframes',\n",
    "        'Clear loser - damages retention',\n",
    "        'Product dilemma: prioritize long-term',\n",
    "        '7-day retention > 1-day for games',\n",
    "        'Insufficient evidence to decide'\n",
    "    ]\n",
    "})\n",
    "\n",
    "display(scenarios)\n",
    "\n",
    "# Actual results\n",
    "print(f\"\\nüéØ YOUR ACTUAL SCENARIO:\")\n",
    "ret1d_sig = ret1d['significant']\n",
    "ret7d_sig = ret7d['significant']\n",
    "ret1d_pos = ret1d['relative_lift'] > 0\n",
    "ret7d_pos = ret7d['relative_lift'] > 0\n",
    "\n",
    "if ret1d_sig and ret1d_pos and ret7d_sig and ret7d_pos:\n",
    "    print(\"   ‚úÖ SHIP - Both metrics improved\")\n",
    "elif ret1d_sig and not ret1d_pos and ret7d_sig and not ret7d_pos:\n",
    "    print(\"   ‚ùå ABANDON - Both metrics worsened\")\n",
    "elif (ret1d_sig and ret1d_pos) and (ret7d_sig and not ret7d_pos):\n",
    "    print(\"   ü§î TRADE-OFF - 1d improved but 7d worsened (prioritize long-term!)\")\n",
    "else:\n",
    "    print(\"   See scenario table above for your specific case\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚úÖ Key Takeaways\n",
    "\n",
    "1. **Always correct for multiple testing** - Testing k metrics inflates false positive rate\n",
    "2. **Bonferroni for few metrics** (k<5), **BH-FDR for many** (k>5)\n",
    "3. **Product decisions are complex** - Metrics often conflict, requires judgment\n",
    "4. **Prioritize long-term metrics** - 7-day retention > 1-day for games\n",
    "5. **Ratio metrics need delta method** - Simple ratio CIs are biased\n",
    "\n",
    "## üìö Next Steps\n",
    "\n",
    "- Try the Criteo notebook (ML-enhanced techniques)\n",
    "- Read about sequential testing (early stopping)\n",
    "- Study CUPAC (ML-enhanced variance reduction)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

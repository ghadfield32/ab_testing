"""
Sequential Testing for A/B Tests
=================================

Methods for early stopping with proper Type I error control when peeking at
results multiple times during an experiment.

Problem: Looking at results k times at Œ±=0.05 ‚Üí actual FWER ‚âà 1-(1-0.05)^k
Solution: Use adjusted boundaries at each interim look

Methods:
- **O'Brien-Fleming**: Conservative early, full power at end (recommended)
- **Pocock**: Constant boundaries, easier to stop early
- **Alpha spending functions**: Flexible error allocation

References:
-----------
- Jennison & Turnbull (1999): "Group Sequential Methods with Applications to Clinical Trials"
- Optimizely (2015): "Stats Engine" white paper on sequential testing

Example Usage:
--------------
>>> from ab_testing.advanced import sequential
>>> import numpy as np
>>>
>>> # Check at 60% information
>>> z_stat = 2.1
>>> boundary = sequential.obrien_fleming_boundary(
...     current_look=3,
...     total_looks=5
... )
>>> can_stop = abs(z_stat) > boundary
>>> print(f"Can stop early: {can_stop}")
"""

import numpy as np
from typing import Dict, Literal, Optional
from scipy import stats


def obrien_fleming_boundary(
    current_look: int,
    total_looks: int,
    alpha: float = 0.05,
    two_sided: bool = True,
) -> float:
    """
    Calculate O'Brien-Fleming stopping boundary at interim look.

    Conservative early, approaches standard z-critical at final look.
    Most commonly used in practice.

    Parameters
    ----------
    current_look : int
        Current interim analysis (1, 2, ..., total_looks)
    total_looks : int
        Total planned number of looks
    alpha : float, default=0.05
        Overall significance level
    two_sided : bool, default=True
        Whether test is two-sided

    Returns
    -------
    float
        Z-statistic boundary for this look

    Formula
    -------
    boundary = z_(Œ±/2) / ‚àö(current_look / total_looks)

    Notes
    -----
    - Early looks have very high boundaries (hard to stop)
    - Final look recovers full power (boundary = 1.96 for Œ±=0.05)
    - Preserves overall Type I error at Œ±

    Example
    -------
    >>> # At 60% information (look 3 of 5)
    >>> boundary = obrien_fleming_boundary(current_look=3, total_looks=5)
    >>> print(f"Need |z| > {boundary:.3f} to stop")
    """
    if current_look < 1 or current_look > total_looks:
        raise ValueError(f"current_look must be between 1 and total_looks")

    # Information fraction
    info_frac = current_look / total_looks

    # Z-critical for overall alpha
    if two_sided:
        z_critical = stats.norm.ppf(1 - alpha/2)
    else:
        z_critical = stats.norm.ppf(1 - alpha)

    # O'Brien-Fleming boundary
    boundary = z_critical / np.sqrt(info_frac)

    return boundary


def pocock_boundary(
    total_looks: int,
    alpha: float = 0.05,
    two_sided: bool = True,
) -> float:
    """
    Calculate Pocock constant stopping boundary.

    Same boundary at all looks (easier to stop early than O'Brien-Fleming).

    Parameters
    ----------
    total_looks : int
        Total planned number of looks
    alpha : float
        Overall significance level
    two_sided : bool
        Whether test is two-sided

    Returns
    -------
    float
        Z-statistic boundary (same for all looks)

    Notes
    -----
    - Constant boundary at all looks
    - Easier to stop early than O'Brien-Fleming
    - Less power at final look
    - Requires simulation/tables to determine boundary

    Example
    -------
    >>> # 5 planned looks
    >>> boundary = pocock_boundary(total_looks=5)
    >>> print(f"Need |z| > {boundary:.3f} at ANY look to stop")
    """
    # Approximate Pocock boundaries (from simulation)
    # Source: Jennison & Turnbull (1999), Table 2.2
    pocock_constants_two_sided = {
        2: 2.178,
        3: 2.289,
        4: 2.361,
        5: 2.413,
        6: 2.453,
        7: 2.485,
        8: 2.512,
        9: 2.535,
        10: 2.555,
    }

    if total_looks not in pocock_constants_two_sided:
        # Approximation for other values
        boundary = 2.0 + 0.5 * np.log(total_looks)
    else:
        boundary = pocock_constants_two_sided[total_looks]

    # Adjust for one-sided if needed
    if not two_sided:
        boundary *= 0.85  # Rough adjustment

    return boundary


def alpha_spending_boundary(
    current_look: int,
    total_looks: int,
    alpha: float = 0.05,
    spending_function: Literal['obf', 'pocock', 'linear'] = 'obf',
    two_sided: bool = True,
) -> float:
    """
    Calculate boundary using alpha spending function.

    More flexible than O'Brien-Fleming or Pocock.
    Can adjust for unequally-spaced looks.

    Parameters
    ----------
    current_look : int
        Current look
    total_looks : int
        Total looks
    alpha : float
        Overall significance level
    spending_function : {'obf', 'pocock', 'linear'}
        Alpha spending function
    two_sided : bool
        Whether test is two-sided

    Returns
    -------
    float
        Z-statistic boundary

    Example
    -------
    >>> boundary = alpha_spending_boundary(3, 5, spending_function='obf')
    """
    if spending_function == 'obf':
        return obrien_fleming_boundary(current_look, total_looks, alpha, two_sided)
    elif spending_function == 'pocock':
        return pocock_boundary(total_looks, alpha, two_sided)
    elif spending_function == 'linear':
        # Linear spending: spend Œ± proportionally to information
        info_frac = current_look / total_looks
        alpha_spent = alpha * info_frac
        if two_sided:
            return stats.norm.ppf(1 - alpha_spent/2)
        else:
            return stats.norm.ppf(1 - alpha_spent)
    else:
        raise ValueError("spending_function must be 'obf', 'pocock', or 'linear'")


def sequential_test(
    z_statistic: float,
    current_look: int,
    total_looks: int,
    alpha: float = 0.05,
    method: Literal['obf', 'pocock'] = 'obf',
) -> Dict[str, any]:
    """
    Perform sequential test with early stopping.

    Parameters
    ----------
    z_statistic : float
        Current test statistic
    current_look : int
        Current interim analysis
    total_looks : int
        Total planned looks
    alpha : float
        Overall significance level
    method : {'obf', 'pocock'}
        Stopping boundary method

    Returns
    -------
    dict
        Dictionary with:
        - boundary: Stopping boundary for this look
        - can_stop: Whether to stop the test
        - decision: 'stop_positive', 'stop_negative', or 'continue'
        - information_fraction: Fraction of data seen
        - looks_remaining: Looks remaining if continue

    Example
    -------
    >>> result = sequential_test(
    ...     z_statistic=2.5,
    ...     current_look=3,
    ...     total_looks=5,
    ...     method='obf'
    ... )
    >>> print(result['decision'])
    """
    # Calculate boundary
    if method == 'obf':
        boundary = obrien_fleming_boundary(current_look, total_looks, alpha, two_sided=True)
    elif method == 'pocock':
        boundary = pocock_boundary(total_looks, alpha, two_sided=True)
    else:
        raise ValueError("method must be 'obf' or 'pocock'")

    # Check stopping criterion
    can_stop = bool(abs(z_statistic) > boundary)  # Convert numpy bool to Python bool

    # Determine decision
    if can_stop:
        # Use standardized decision strings that match test expectations
        decision = 'reject_null'  # Stop for statistical significance
    else:
        decision = 'continue'

    # Information fraction
    info_frac = current_look / total_looks

    return {
        'boundary': float(boundary),
        'can_stop': can_stop,
        'decision': decision,
        'z_statistic': float(z_statistic),
        'information_fraction': float(info_frac),
        'current_look': int(current_look),
        'total_looks': int(total_looks),
        'looks_remaining': int(total_looks - current_look) if not can_stop else 0,
    }


def obrien_fleming_boundaries(
    n_looks: int,
    alpha: float = 0.05,
    two_sided: bool = True,
) -> Dict[str, any]:
    """
    Calculate O'Brien-Fleming boundaries for all planned looks.

    Convenience function to get all boundaries at once.

    Parameters
    ----------
    n_looks : int
        Total number of planned interim analyses
    alpha : float, default=0.05
        Overall significance level
    two_sided : bool, default=True
        Whether test is two-sided

    Returns
    -------
    dict
        Dictionary with:
        - boundaries: List of boundaries for each look
        - n_looks: Number of looks
        - alpha: Significance level
        - two_sided: Whether two-sided

    Example
    -------
    >>> result = obrien_fleming_boundaries(n_looks=5, alpha=0.05)
    >>> print(result['boundaries'])
    [4.38, 3.10, 2.53, 2.19, 1.96]
    """
    boundaries = []
    for look in range(1, n_looks + 1):
        boundary = obrien_fleming_boundary(look, n_looks, alpha, two_sided)
        boundaries.append(boundary)

    return {
        'boundaries': boundaries,
        'n_looks': n_looks,
        'alpha': alpha,
        'two_sided': two_sided,
    }


def alpha_spending_function_obf(
    current_look: int,
    total_looks: int,
    alpha: float = 0.05,
) -> float:
    """
    Calculate cumulative alpha spent using O'Brien-Fleming spending function.

    This returns how much of the total alpha has been "spent" by this look.

    Parameters
    ----------
    current_look : int
        Current interim analysis (1, 2, ..., total_looks)
    total_looks : int
        Total planned number of looks
    alpha : float, default=0.05
        Overall significance level

    Returns
    -------
    float
        Cumulative alpha spent up to this look

    Formula
    -------
    For O'Brien-Fleming, the alpha spending function is:
    Œ±(t) = 2 * [1 - Œ¶(z_{Œ±/2} / ‚àöt)]
    where t is the information fraction (current_look / total_looks)

    Notes
    -----
    - At final look, returns full alpha
    - Monotonically increasing
    - Based on cumulative normal distribution

    Example
    -------
    >>> alpha_spent = alpha_spending_function_obf(3, 5, 0.05)
    >>> print(f"Alpha spent: {alpha_spent:.4f}")
    """
    if current_look < 1 or current_look > total_looks:
        raise ValueError(f"current_look must be between 1 and total_looks")

    # Information fraction
    info_frac = current_look / total_looks

    # Z-critical for overall alpha (two-sided)
    z_critical = stats.norm.ppf(1 - alpha/2)

    # O'Brien-Fleming alpha spending function
    # Œ±(t) = 2 * [1 - Œ¶(z_{Œ±/2} / ‚àöt)]
    alpha_spent = 2 * (1 - stats.norm.cdf(z_critical / np.sqrt(info_frac)))

    return alpha_spent


def recommended_looks(
    experiment_duration_days: int,
    min_days_between_looks: int = 7,
) -> Dict[str, any]:
    """
    Recommend number of interim looks based on experiment duration.

    Provides practical guidance on how many times to analyze results.

    Parameters
    ----------
    experiment_duration_days : int
        Total planned duration of experiment in days
    min_days_between_looks : int, default=7
        Minimum days between interim analyses (weekly by default)

    Returns
    -------
    dict
        Dictionary with:
        - recommended_looks: Number of looks to plan
        - look_frequency_days: Days between looks
        - rationale: Explanation of recommendation

    Guidelines
    -----------
    - Industry standard: Weekly looks for 4+ week experiments
    - Minimum: 7 days between looks (avoid daily peeking)
    - Maximum: 5-7 looks (more looks = more complexity)

    Example
    -------
    >>> rec = recommended_looks(experiment_duration_days=28)
    >>> print(f"Recommended: {rec['recommended_looks']} looks every {rec['look_frequency_days']} days")
    """
    # Calculate maximum looks based on minimum frequency
    max_looks = experiment_duration_days // min_days_between_looks

    # Apply practical constraints
    if max_looks <= 1:
        recommended = 1
        rationale = "Experiment too short for multiple looks. Analyze once at end."
    elif max_looks == 2:
        recommended = 2
        rationale = f"Two looks: mid-point and final (every {min_days_between_looks} days)."
    elif max_looks <= 5:
        recommended = max_looks
        rationale = f"{max_looks} looks every {min_days_between_looks} days is manageable."
    else:
        # Cap at reasonable number
        if min_days_between_looks == 7:
            # Weekly looks are standard
            recommended = max_looks
            rationale = f"Weekly analysis ({max_looks} looks) is industry standard."
        else:
            # For other frequencies, cap at 7 looks
            recommended = min(max_looks, 7)
            if recommended < max_looks:
                rationale = f"Capped at {recommended} looks for simplicity (could do up to {max_looks})."
            else:
                rationale = f"{recommended} looks every {min_days_between_looks} days."

    look_frequency = experiment_duration_days / recommended if recommended > 0 else experiment_duration_days

    return {
        'recommended_looks': recommended,
        'look_frequency_days': int(look_frequency),
        'rationale': rationale,
        'experiment_duration_days': experiment_duration_days,
        'min_days_between_looks': min_days_between_looks,
    }


def fwer_inflation_no_correction(
    n_looks: int,
    alpha: float = 0.05,
) -> float:
    """
    Calculate FWER inflation from peeking without correction.

    Shows how much Type I error inflates with repeated testing.

    Parameters
    ----------
    n_looks : int
        Number of times you peek at results
    alpha : float
        Nominal significance level per look

    Returns
    -------
    float
        Actual FWER

    Formula
    -------
    FWER ‚âà 1 - (1 - Œ±)^n (Pocock approximation)

    Example
    -------
    >>> fwer = fwer_inflation_no_correction(n_looks=5, alpha=0.05)
    >>> print(f"Peeking 5 times: {fwer:.1%} false positive rate")
    """
    # Pocock approximation
    return 1 - (1 - alpha)**n_looks


def compare_boundaries(total_looks: int = 5, alpha: float = 0.05) -> Dict[str, any]:
    """
    Compare O'Brien-Fleming vs Pocock boundaries.

    Parameters
    ----------
    total_looks : int
        Total number of planned looks
    alpha : float
        Overall significance level

    Returns
    -------
    dict
        Comparison of boundaries at each look

    Example
    -------
    >>> comparison = compare_boundaries(total_looks=5)
    >>> print(comparison['boundaries_table'])
    """
    obf_boundaries = []
    pocock_boundary_val = pocock_boundary(total_looks, alpha)

    for look in range(1, total_looks + 1):
        obf_bound = obrien_fleming_boundary(look, total_looks, alpha)
        info_frac = look / total_looks
        obf_boundaries.append({
            'look': look,
            'information_fraction': info_frac,
            'obf_boundary': obf_bound,
            'pocock_boundary': pocock_boundary_val,
        })

    return {
        'total_looks': total_looks,
        'alpha': alpha,
        'boundaries_table': obf_boundaries,
        'standard_z': stats.norm.ppf(1 - alpha/2),  # For comparison
    }


if __name__ == "__main__":
    # Demo
    print("=" * 80)
    print("Sequential Testing Demo")
    print("=" * 80)

    # Scenario: Experiment with 5 planned looks
    total_looks = 5
    alpha = 0.05

    print("\nüìä STOPPING BOUNDARIES COMPARISON")
    print("-" * 80)
    comparison = compare_boundaries(total_looks=total_looks)

    print(f"Total looks: {total_looks}")
    print(f"Overall Œ±: {alpha}")
    print(f"Standard z-critical (no correction): {comparison['standard_z']:.4f}")
    print()

    print(f"{'Look':>6} {'Info %':>8} {'O\'Brien-Fleming':>18} {'Pocock':>12}")
    print("-" * 50)

    for row in comparison['boundaries_table']:
        print(f"{row['look']:>6} {row['information_fraction']*100:>7.0f}% "
              f"{row['obf_boundary']:>18.4f} {row['pocock_boundary']:>12.4f}")

    # Example: Test at look 3
    print("\nüìä EXAMPLE: INTERIM ANALYSIS AT LOOK 3")
    print("-" * 80)
    z_stat = 2.1
    result = sequential_test(
        z_statistic=z_stat,
        current_look=3,
        total_looks=5,
        method='obf'
    )

    print(f"Current z-statistic: {z_stat:.4f}")
    print(f"Current look: {result['current_look']} of {result['total_looks']}")
    print(f"Information fraction: {result['information_fraction']:.0%}")
    print(f"O'Brien-Fleming boundary: {result['boundary']:.4f}")
    print(f"|z| > boundary? {abs(z_stat):.4f} > {result['boundary']:.4f} ‚Üí {'Yes' if result['can_stop'] else 'No'}")
    print(f"\nDecision: {result['decision'].upper().replace('_', ' ')}")

    if result['decision'] == 'continue':
        print(f"Looks remaining: {result['looks_remaining']}")

    # Show FWER inflation
    print("\n‚ö†Ô∏è IMPORTANCE OF CORRECTION")
    print("-" * 80)
    fwer = fwer_inflation_no_correction(n_looks=5, alpha=0.05)
    print(f"Without correction: FWER = {fwer:.1%} (should be 5.0%!)")
    print(f"With O'Brien-Fleming: FWER = 5.0% (controlled)")
